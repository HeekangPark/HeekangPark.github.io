---
title: "선형 분류 (Linear Classification)"
order: 3
date_created: "2020-12-23"
date_modified: "2021-11-04"
---

[Linear Classification note](http://cs231n.github.io/linear-classify)

# Linear Classification

지난 글에서 우리는 이미지에 대해 사전에 정해진 카테고리 집합으로부터 하나의 레이블을 배정하는 이미지 분류 문제에 대해 배웠다. 또한 우리는 테스트 이미지와 레이블링 된 학습 셋의 이미지들을 비교하여 테스트 이미지의 레이블을 예측하는 kNN 분류기에 대해서도 배웠다. 그러나 함께 살펴보았다시피 kNN에는 몇 가지 단점이 있다.

- 분류기는 테스트 데이터와 비교할 수 있도록 반드시 모든 학습 데이터를 기억하고 있어야 한다. 데이터 셋의 크기는 일반적으로 기가바이트 단위를 넘는 경우가 많으므로, 이는 공간적으로 아주 비효율적이다.
- 테스트 이미지 하나를 분류하기 위해서는 모든 학습 데이터와의 비교 연산이 필요하므로 비용이 많이 든다.

## Overview

우리는 훨신 더 강력한 이미지 분류 기법인 선형 분류(Linear Classification)에 대해 배울 것이다. 이 기법은 NN(Neural Network)와 CNN(Convolutional Neural Network)로 발전하게 된다. 이 기법에는 원본 데이터를 클래스 점수로 바꿔 주는 **점수 함수(score function)**와, 예측된 점수들과 참값 레이블이 얼마나 일치하는지를 수량화한 **손실 함수(loss function)**, 이렇게 두 가지 중요한 요소가 있다. 이들을 이용하면 이미지 분류 문제를 점수 함수의 파라미터에 대해 손실 함수를 최소화하는 최적화 문제(optimization problem)로 바꿀 수 있다.

# Parameterized mapping from images to label scores

선형 분류를 사용하기 위해 가장 먼저 해야 할 것은 이미지의 픽셀 값들을 각 클래스에 대한 신뢰도 점수(confidence score)로 바꾸는 점수 함수(score function)를 정의하는 것이다. 예제와 함께 살펴보자. $i = 1, 2, \cdots, N$에 대해, 학습 데이터 셋의 이미지 $x\_i \in \mathbb{R}^D $와 이에 상응하는 레이블 $y\_i \in \\{ 1, 2, \cdots, K \\}$가 주어졌다고 하자(즉, D차원의 데이터 N개와 그 레이블이 주어졌고, 레이블은 K개의 카테고리로 구성된다). 예를 들어, CIFAR-10의 경우 $N = 50,000$개의 이미지로 구성되어 있고, 각각의 이미지는 $D=32 \times 32 \times 3 = 3072$개의 픽셀로 구성되며, 10개의 클래스가 있으므로 $K=10$이다. 이제 이미지의 픽셀들을 클래스 점수로 바꿔주는 점수 함수 $f : \mathbb{R}^D \to \mathbb{R}^K$를 정의하자.

## Linear Classifier

선형 분류기(Linear classifier)는 다음과 같은 선형 함수(Linear function)를 점수 함수로 사용한다.

$$f(x_i, W, b) = Wx_i + b$$

$x\_i$는 입력 이미지의 모든 픽셀들이 $D \times 1$ 크기의 단일 열 벡터(single column vector)로 평탄화되어 있는(flatten) 것이다. 크기 $K \times D$짜리 배열 $W$와 크기 $K \times 1$짜리 벡터 $b$는 이 함수의 **파라미터(parameter)**이다. CIFAR-10에서 예로 들면, $x\_i$는 $i$번째 이미지를 3072 × 1 크기로 평탄화시킨 벡터이고, $W$는 10 × 3072, $b$는 10 × 1 크기의 벡터이다. $f$는 3072개의 수(픽셀 원본 값)를 입력받아 10개의 수(클래스 점수)를 출력하는 함수이다. 파라미터 $W$는 **가중치(weight)**라고도 불리고, 파라미터 $b$는 최종 출력되는 점수에는 영향을 끼치지만 실제 데이터 $x\_i$와 상호작용을 하진 않기에 **편향 벡터(bias vector)**라고도 불린다. 파라미터와 가중치라는 용어는 자주 혼용된다.

선형 분류기의 선형 함수는 다음과 같은 특징이 있다.

- $W$의 각 행은 하나의 분류기를 의미한다. 행렬곱 연산($Wx_i$) 한 번으로 각 클래스에 대해 10개의 독립적인 분류기를 동시에 사용할 수 있으므로 아주 효율적이다.
- 선형 분류기의 목표는 $W$와 $b$를 적절히 수정해 전체 데이터 셋에 대해 계산된 점수가 참값 레이블과 동일하도록 만드는 것이다. $(x\_i, y\_i)$는 고정된 값으로, 수정하지 않는다. 이를 어떻게 할 지는 조금 있다가 더 자세히 알아볼 것이다. 간단히 말하면 정답 클래스의 점수가 오답 클래스의 점수들보다 더 높게 만들면 된다.
- 이 기법에서 학습 데이터는 파라미터 $W$, $b$를 학습시키기 위해 사용된다. 학습이 완료되면 학습된 파라미터만 가지고 있어도 되므로 전체 학습 데이터를 폐기해도 된다. 새로운 테스트 이미지는 점수 함수가 계산한 클래스 점수만 이용해 분류할 수 있다.
- 테스트 이미지를 분류하는 작업은 행렬곱 연산과 행렬합 연산 한 번으로 구성된다. 이는 전체 학습 이미지들과 테스트 이미지를 비교하는 것에 비하면 압도적으로 빠른 방법이다.

> 예고) CNN도 위에서처럼 이미지 픽셀들을 점수로 변환한다. 다만 점수 함수($f$)가 훨씬 복잡하고, 더 많은 파라미터를 사용한다.

# Interpreting a linear classifier

선형 분류기는 이미지의 전체 3개 채널의 모든 픽셀값들의 가중합(weighted sum)을 구해 각 클래스의 점수를 구한다. 가중치에 어떤 값이 설정되었는지에 따라 점수 함수는 이미지의 특정 위치의 특정 색을 좋아할 수도(가중치 부호가 +일 때) 좋아하지 않을 수도(가중치 부호가 -일 때) 있다. 예를 들어, "배(ship)" 클래스로 분류될 이미지에는 이미지 한편에 파란색이 많을 것이다(아마도 물을 나타내고 있을 것이다). 그렇다면 "배" 분류기는 파란색 채널의 가중치 값에는 양수가 많을 것이고(= 파란색의 존재는 "배" 클래스의 점수를 높인다), 빨간색/초록색 채널의 가중치 값에는 음수가 많을 것이다(= 빨간색/초록색의 존재는 "배" 클래스의 점수를 낮춘다).

{% include caption-img.html src="https://cs231n.github.io/assets/imagemap.jpg" outside_img="true" description="이미지를 클래스 점수로 변환하는 예제. 이미지가 단일 색상(monochrome) 픽셀 4개로만 이루어져 있다고 가정하자(간결성을 위해 색 채널은 고려하지 말자). 빨간색(고양이), 초록색(강아지), 파란색(배), 이렇게 3개의 클래스가 주어졌다고 하자(색깔들은 3개의 클래스를 구분하기 위해 부여되었지, RGB 채널을 의미하지 않는다). 이미지 픽셀들을 하나의 열(column) 벡터로 만든 후 행렬곱 연산을 수행해 각각의 클래스에 대한 점수를 구한다. 참고로 현재 가중치 값들의 행렬 $W$는 별로 좋지 않은 값이다. $W$는 고양이 사진이 입력되었지만 고양이 클래스의 점수를 아주 낮게 부여하였다. 현재의 $W$는 이 이미지가 강아지일 거라고 추정하고 있다." %}

## Analogy of image as high-dimensional points

이미지를 고차원의 열 벡터로 변형하면 이미지 각각을 고차원 공간의 한 점으로 해석할 수 있다. 예를 들어, CIFAR-10의 각각의 이미지는 3072(= 32×32×3)차원 공간 상의 한 점이라 해석할 수 있다. 즉 전체 데이터 셋은 레이블링 된 점들의 집합이라 할 수 있다.

이미지의 클래스 점수는 전체 픽셀들의 가중합(weighted sum)으로 정의되므로, 각 클래스 분류기는 고차원 공간 상의 선형 함수가 된다. 안타깝게도 3072차원 공간을 시각화할 수는 없으므로, 다음과 같이 차원을 뭉개 2차원으로 만들어 분류기들을 시각화할 수 있다.

{% include caption-img.html src="https://cs231n.github.io/assets/pixelspace.jpeg" outside_img="true" description="이미지 공간을 표현한 이미지. 데이터 셋의 각 이미지들은 하나의 점으로, 선형 분류기는 선으로 표현되어 있다. 예를 들어 자동차 분류기(빨간색)의 경우 공간 상에서 자동차 클래스 점수가 0이 나오는 모든 점들을 이은 것이다. 이때 빨간 화살표는 클래스 점수가 증가하는 방향을 보여준다. 즉, 빨간 선 오른편의 모든 점들은 (화살표 방향으로 선형적으로 증가하는) 양수 점수를 가지고, 빨간 선 왼편의 모든 점들은 (화살표 방향으로 선형적으로 감소하는) 음수 점수를 가진다." %}

$W$의 각 행은 각각 클래스 하나에 대한 분류기이다. 만약 $W$의 한 행을 수정하면 해당 행과 대응되는 분류기를 나타내는 이미지 공간 상의 직선이 회전한다. 또한 편향 $b$는 선들을 대칭이동시킨다. 편향 항이 없는 경우 모든 선들은 (강제적으로) 원점을 지나게 된다($x\_i = 0$을 점수 함수에 대입하면 가중치 값과 상관없이 항상 0이 나오기 때문이다).

## Interpretation of linear classifiers as template matching

가중치 $W$에 대한 또 다른 해석은 $W$의 각 행이 각각 클래스 하나에 대한 템플릿(template) 또는 프로토타입(prototype)이라 보는 것이다. 클래스 점수는 클래스의 템플릿과 이미지를 하나씩 내적(inner product, dot product)하여 구한다. 선형 분류기는 학습된 템플릿들을 이용해 가장 "잘 맞는" 템플릿을 찾는 것이라 할 수 있다. 즉 선형 분류기는 여전히 최근접 이웃(Nearest Neighbor)을 찾고 있는데, 이번에는 수천장의 모든 학습 이미지들을 다 가지고 있는 것이 아니라 각 클래스 당 딱 한장의 템플릿 이미지만 가지고, L1, L2 Distance를 사용하는 대신 음의 내적(negative inner product)을 사용하는 것이다. 선형 분류기가 가지고 있는 템플릿 이미지는 학습을 통해 만들어진다. 템플릿 이미지는 학습 데이터의 사진 중 한 장일 필요는 없다.

{% include caption-img.html src="https://cs231n.github.io/assets/templates.jpg" outside_img="true" description="CIFAR-10에 대해 학습이 완료된 템플릿(가중치)들의 예. 예상한 대로 \"배(ship)\" 템플릿에 파란색 픽셀이 많은 것을 볼 수 있다. 배 템플릿과 바다 위의 배 이미지들과의 내적을 구하면 \"잘 맞으므로\" 선형 분류기는 이들 이미지에게 배 클래스에 대해 높은 점수를 주게 된다." %}

추가로, "말(horse)" 템플릿이 머리가 2개인 말 이미지처럼 보이는 것을 볼 수 있다. 이는 데이터 셋에 왼쪽을 바라보고 있는 말 이미지와 오른쪽을 바라보고 있는 말 이미지가 있었기 때문이다. 선형 분류기는 학습되며 데이터 셋에서 이 두 종류의 말들을 합쳐 하나의 이미지로 만들었다. 비슷하게, 자동차 분류기는 자동차의 모든 면을 식별할 수 있도록 다양한 종류의 차들이 하나의 템플릿으로 합쳐져 있는 것으로 보인다. 또한 자동차 템플릿은 빨간색으로 보이는데, CIFAR-10에 다른 색보다 빨간 색 차가 많기 때문이다. 참고로 선형 분류기는 다른 색의 자동차를 잘 분류하기에는 너무 약하지만, 나중에 살펴볼 NN(Neural Network)는 이를 분류하는 것이 가능하다. 미리 조금 살펴보면, NN은 은닉 계층(hidden layer)에 "왼쪽을 보고 있는 초록색 자동차", "정면을 바라보고 있는 파란색 자동차"와 같이 명확한 자동차 종류들을 감지할 수 있는 뉴런들이 있고, 다음 계층의 뉴런들이 각각의 자동차 감지기들의 출력 결과들의 가중합을 구해 조금 더 정확한 자동차 클래스 점수를 구할 수 있다.

## Bias trick

다음 단계에 나아가기 앞서 두개의 파라미터 $W$, $b$를 하나로 만드는 잘 알려진 단순화 기법을 살펴보자. 위에서 우리는 점수 함수를 다음과 같이 정의하였다.

$$f(x_i, W, b) = Wx_i + b$$

가중치 $W$와 편향 $b$, 이렇게 두 개의 파라미터를 따로따로 들고 다니는 것은 조금 번거롭다. 이때 $x\_i$에 상수 1로 채워진 차원(편향 차원(bias dimension))을 하나 추가하면 두 개의 파라미터를 하나의 행렬로 만들 수 있다. 이 추가적인 차원을 이용하면 새로운 점수 함수를 다음과 같이 행렬곱 연산 하나로 단순화시킬 수 있다.

$$f(x_i, W) = Wx_i$$

예를 들어 CIFAR-10에서 $x\_i$의 크기는 상수 1을 담고 있는 여분 차원이 추가되어 3072 × 1이 아닌 3073 × 1이 된다. $W$의 크기는 10 × 3072가 아닌, 편향 $b$에 해당하는 새로운 열이 추가되어 10 × 3073이 된다. 다음 그림을 참고하라.

{% include caption-img.html src="https://cs231n.github.io/assets/wb.jpeg" outside_img="true" description="Bias trick 예시. 행렬곱 연산 후 편향 벡터(bias vector)를 더하는 것(왼쪽)은 모든 입력 벡터에 상수 1로 채워진 편향 차원(bias dimension)을 추가하고 가중치에 새로운 열을 추가하는 것(오른쪽)과 동일하다. 따라서 입력 벡터에 1을 추가하는 전처리를 하게 되면 이전처럼 두 개의 행렬(가중치와 편향)이 아닌 하나의 행렬만 학습시키면 되어 편리하다." %}

## Image data preprocessing

위 예시에서 우리는 [0...255] 범위의 값을 가지는 원본 픽셀 값들을 사용하였다. 기계학습에서 입력 feature(이미지의 경우, 픽셀 하나하나가 feature라 생각하면 된다)를 정규화(normalization)하는 것은 아주 흔히 사용되는 기법이다. 구체적으로, 전체 feature에서 평균(mean)을 빼 **데이터를 가운데로 모으는 것**이 중요하다. 이미지의 경우, 학습 이미지들의 평균 이미지(mean image)를 구해 이를 각각의 이미제 대해서 빼 픽셀들의 값이 대략적으로 [-127...127] 범위가 되게 한다. 흔히 사용되는 또 다른 전처리 기법으로는 입력 feature들의 크기를 조정해 값들의 범위가 [-1, 1] 사이에 오도록 하는 것이 있다. 평균 0으로의 정렬은 중요하지만, 이를 제대로 이해하려면 경사하강법(gradient descent)의 특성들에 대한 이해가 필요하므로 여기서는 적용하지 않겠다.

# Loss function

이전 섹션에서 우리는 픽셀 값들을 클래스 점수로 바꾸어 주는 점수 함수를 정의하였다. 점수 함수는 가중치들의 집합 $W$를 파라미터로 사용한다. 데이터 $(x\_i, y\_i)$를 조작하지 않고(데이터는 고정된 값으로 주어졌다) 가중치들만 조절해 학습 데이터에 대해 예측된 클래스 점수와 참값 레이블이 동일하도록 해야 한다.

예를 들어 위에서 그림으로 살펴본 고양이 이미지의 "고양이(cat)", "강아지(dog)", "배(ship)" 클래스에 대한 점수를 계산하는 예시에서, 현재 사용하고 있는 가중치 값들은 좋은 선택이 아니라는 것을 보았다. 우리는 고양이 이미지를 입력했지만, 출력된 "고양이" 클래스 점수는 다른 클래스 점수("강아지": 437.9, "배": 61.95)에 비해 매우 낮았다(-96.8). 우리는 이제 **손실 함수(loss function, cost function, objective)**를 이용해 이 경우 우리가 얼마나 안 기쁜지를 측정할 것이다. 간단히 말해 학습 데이터를 잘 분류하지 못하면 이 손실값(loss)은 커지고, 잘 분류하면 작아져야 한다.

## Multiclass Support Vector Machine loss

손실 함수에는 여러 가지 종류가 있다. 첫 번째 예로 우리가 사용할 손실 함수는 **SVM(Multiclass Support Vector Machine) 손실 함수**라 불리는 유명한 손실 함수이다. SVM 손실 함수는 정답 클래스의 점수가 정답이 아닌 클래스의 점수보다 특정 값(margin) $\Delta$보다 크기를 "원한다". 참고로 방금 한 것처럼 손실 함수를 의인화하는 것은 손실 함수의 동작을 이해하는데 도움이 된다. 손실 함수가 특정 결과가 나오기를 "원한다"는 말의 뜻은 해당 특정 결과가 나올 때 손실값이 작아진다는 것이다(손실값이 작아지는 것은 좋은 것이다).

조금 더 정확히 알아보자. $i$번째 이미지의 전체 픽셀을 하나의 열 벡터로 만든 $x\_i$와 해당 이미지의 레이블 $y\_i$가 주어졌다고 해 보자. 점수 함수 $f$는 $x\_i$를 입력받아 클래스 점수를 나타내는 벡터 $s = f(x\_i, W)$를 출력한다($s$는 score를 줄인 것이다). $x\_i$의 $j$번째 클래스의 점수는 $s\_j$의 $j$번째 요소인 $s\_j = f(x\_i, W)\_j$라 표현할 수 있다. $i$번째 이미지에 대한 SVM 손실 함수는 다음과 같다.

$$L_i = \sum _{j \neq y_i } {\max (0, \, s_j - s_{y_i} + \Delta)}$$

## Example

예제와 함께 위 식을 조금 더 자세히 살펴보자. 세 가지 클래스가 있는 한 이미지 분류 문제에서 각 클래스의 점수가 $s$ = [13, -7, 11]으로 나왔고, 이 중 첫 번째 클래스가 참값이라(즉 $y\_i = 0$이라) 가정하자. 또한 $\Delta = 10$이라 가정하자($\Delta$는 하이퍼파라미터로서, 나중에 조금 더 자세히 다루도록 하겠다). 위 식은 모든 오답 클래스($j \neq y_i$)에 대한 합을 구하는 식이므로, 이 경우 다음과 같이 식을 쓸 수 있다.

$$L_i = \max (0,\,-7-13+10) + \max (0,\,11-13+10)$$

이때 $-7-13+10$은 음수가 나오므로 첫 번째 항은 $\max(0, \, -)$ 함수에 의해 0이 된다. 정답 클래스의 점수(13)가 오답 클래스의 점수(-7)보다 $\Delta = 10$ 이상 크므로 loss값이 0이 나온 것이다. 사실 정확히 말하면 두 점수의 차이는 10보다 큰 20이지만, SVM 손실 함수는 점수의 차이가 10보다 큰지 아닌지에만 관심이 있다. 두 번째 항에서는 $11-13+10$이 계산되어 8이 된다. 비록 정답 클래스의 점수는 오답 클래스의 점수보다 크지만(13 > 11), 그 차이가 $\Delta = 10$보다 작은 2밖에 나지 않아 8이 나온다. 8은 클래스 점수의 차이가 $\Delta$에 다다르기 위해 더 커저야 하는 크기를 의미한다고 이해하면 된다. 요약하면, SVM 손실 함수는 정답 클래스 $y\_i$의 클래스 점수가 다른 모든 오답 클래스 점수들보다 최소 $\Delta$ 이상 크길 바란다. 만약 이를 충족시키지 못했다면 손실값은 증가한다.

현재 우리는 선형 점수 함수($f(x\_i \; W) = Wx_i$)를 사용하고 있으므로, 손실 함수를 다음과 같은 형태로 재작성할 수 있다($w\_j$는 $W$의 $j$번째 행을 열로 바꾼 것을 의미한다).

$$L_i = \sum _{j \neq y_i } {\max (0, \, w_j ^T x_i - w_{y_i} ^T x_i + \Delta)}$$

마지막으로 살펴볼 것은 **힌지 손실 함수(hinge loss)**라 불리는, 0에 대한 문턱값(threshold)을 나타내는 $\max (0, \, -)$ 함수이다. 가끔 정답 클래스와 오답 클래스의 차가 $\Delta$보다 작은 항을 더 강하게 불리하게 만들기 위해 선형적인 식이 아닌 2차식 형태의 제곱 힌지 손실 SVM 함수(squared hinge loss SVM, 혹은 L2-SVM, $\max (0, \, -)^2 $)을 대신 사용할 때도 있다. 제곱하지 않은 단순한 힌지 손실 함수를 사용하는 것이 더 일반적인 형태이나, 몇몇 데이터 셋에서는 제곱 힌지 손실 함수가 더 잘 작동할 수 있다. 두 손실값 중 어느쪽이 더 나은지는 교차 검증법(cross validation)을 적용해 결정하면 된다.

> 손실 함수는 우리가 학습 데이터에 대한 예측 값들에 얼마나 불만족하는지를 정량화해준다.

{% include caption-img.html src="https://cs231n.github.io/assets/margin.jpg" outside_img="true" description="Multiclass SVM 손실 함수는 정답 클래스의 점수가 다른 클래스 점수에 비해 최소 $\Delta$ 이상 크기를 \"원한다\". 만약 어떤 오답 클래스의 점수가 빨간 영역 혹은 그 이상의 영역에 있으면 손실값은 커진다. 그런 오답 클래스 점수가 없다면 손실값은 0이 된다. 우리의 목표는 학습 데이터 안의 모든 데이터들이 동시에 이 제약 조건을 만족하면서 전체 손실값이 가능한 한 최소가 되도록 하는 가중치를 찾는 것이다." %}

## Regularization

위에서 살펴본 손실 함수에는 하나의 버그가 있다. 우리에게 데이터 셋과 이 데이터 셋 안의 모든 데이터들을 잘 분류하는 파라미터 $W$가 주어졌다고 해 보자(즉, 모든 오답 클래스 점수들은 정답 클래스 점수보다 $\Delta$ 이상 작고, 모든 $i$에 대해 $L\_i = 0$이다). 문제는 $W$가 유일하지 않다는 것이다: 아마 데이터들을 올바르게 분류하는 유사한 $W$가 많이 있을 것이다. 이는 다음 방법으로 간단하게 증명할 수 있다. 만약 어떤 파라미터 $W$가 모든 데이터들을 맞게 분류했다면(= 모든 데이터에 있어 손실값이 0이 된다면) 이 파라미터의 어떠한 배수 $\lambda W$를 사용해도 손실값이 0이 될 것이다($\lambda > 1$). 왜냐하면 $\lambda$를 곱하는 것은 클래스 점수들의 크기를 같은 비율로 키울 것이고, 클래스 점수간 차이의 절대값 역시 늘어날 것이기 때문이다. 예를 들어, 만약 정답 클래스와 가장 가까운 오답 클래스 간의 점수 차이가 15였다면 $W$의 모든 원소에 2를 곱하는 것은 이 차이를 30이 되게 한다.

우리는 이런 모호성을 없앨 수 있도록 어떤 가중치 집합 $W$가 다른 가중치 집합들에 비해 더 크게 선호되도록 만들고 싶다. 이는 기존 손실 함수에 **규제화 패널티(Regularization penalty)** 항 $R(W)$를 추가하는 것으로 할 수 있다. 가장 흔한 규제화 패널티는 전체 파라미터의 각 원소를 제곱한 L2 norm으로, 큰 가중치가 나오지 않게 한다.

$$R(W) = \sum _{k} \sum _l W^2 _{k,\, l}$$

위 수식은 $W$의 모든 원소들의 제곱을 더하고 있다. 규제화 패널티는 입력 데이터에 관한 함수가 아닌 가중치만을 변수로 가지는 함수임을 유의해서 보자. 규제화 패널티를 추가하면 SVM 손실 함수를 완성할 수 있다. SVM 손실 함수는 **데이터에 의한 손실값(data loss)** 항(= 모든 데이터들에 대한 손실값 $L\_i$의 평균)과 **규제화에 의한 손실값(regularization loss)**항으로 구성된다. 즉, $N$을 전체 학습 데이터의 수라고 할 때, 전체 SVM 손실 함수는 다음과 같이 생겼다.

$$L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss}$$

또는 다음과 같이 모두 전개한 형태로 표현할 수도 있다.

$$L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2$$

수식에서 볼 수 있다시피 우리는 손실 함수에 하이퍼파라미터 $\lambda$를 가지는 규제화 패널티 항을 추가했다. $\lambda$를 잘 설정하는 간단한 방법은 없고, 일반적으로 교차 검증법을 통해 결정한다.

규제화 패널티를 추가하면 위에서 설명한 것 이외에도 추가적으로 얻을 수 있는 매력적인 특성들이 많다. 나중에 이들에 대해 더 깊게 배울 것이다. 예를 들면, L2 패널티(L2 penalty)를 추가하는 것은 SVM 손실 함수에 **max margin** 특성을 부여한다고 알려져 있다.

큰 가중치 값에 패널티를 줄 때의 가장 매력적인 특성은 일반화(generalization)가 더 잘된다는 것이다. 큰 가중치에 패널티를 주면 어떠한 입력 차원도 그 혼자서 클래스 점수에 아주 큰 영향을 끼칠 수 없기 때문이다. 예를 들어, 입력 벡터 $x=[1, \, 1, \, 1, \, 1]$와 두 개의 가중치 벡터 $w\_1 = [1, \, 0, \, 0, \, 0]$, $w\_2 = [0.25, \, 0.254, \, 0.25, \, 0.25]$가 주어졌다고 해 보자. 입력값과 두 가중치 벡터의 내적값은 $w\_1 ^T x = w\_2 ^T x = 1$로 동일하나, $w\_2$의 L2 패널티는 0.25밖에 안 될때 $w\_1$의 L2 패널티는 1.0이나 된다. 그 결과 가중치 벡터 $w\_2$가 더 낮은 규제화에 의한 손실값을 가지므로 더 선호된다. 직관적으로 이것은 $w\_2$ 안에 있는 가중치들이 더 작고 더 분산되어 있기 때문이다. L2 패널티는 더 작고 더 분산되어 있는 가중치 벡터를 선호하므로, 최종적으로 만들어진 위 분류기는 몇몇 입력 차원만 엄청 큰 값을 가지는 형태보다 전체적인 차원이 고루 작은 값을 가진 형태가 되도록 유도한다. 나중에 더 자세히 다루겠지만, 이 효과는 분류기의 테스트 이미지에 대한 일반화 성능을 높이고 과적합(overfitting)이 더 적게 일어나도록 한다.

참고로 편향은 가중치와 다르게 입력 차원의 영향력을 강화한다던가 하는 효과가 없다. 따라서 일반적으로 가중치들($W$)은 규제해도 편향($b$)은 규제하지 않는다. 또한 규제화 패널티 때문에 이젠 절대로 전체 데이터에 대한 손실값이 0이 되게 만들 수 없다. 전체 데이터에 대한 손실값이 0이 나오려면 $W = 0$일 때만 가능하기 때문이다.

## Code

다음은 파이썬으로 손실 함수를 구현한 예이다(규제화는 사용하지 않았다).

{% highlight python %}
def L_i(x, y, W):
  """
  벡터화하지 않은 버전. 하나의 데이터 (x, y)에 대한 SVM 손실값을 계산한다.
  - x : 이미지 한 장을 나타내는 열 벡터. 가장 마지막에 편향을 위한 차원이 추가되어 있다(bias trick). (ex. CIFAR-10의 경우, 크기 3073 x 1)
  - y : 정답 클래스의 인덱스를 나타내는 정수 (ex. CIFAR-10의 경우, 0~9 사이의 정수)
  - W : 가중치 행렬 (ex. CIFAR-10의 경우, 크기 10 x 3073)
  """
  delta = 1.0
  scores = W.dot(x) # scores : 클래스 점수들을 나타내는 열 벡터 (ex. CIFAR-10의 경우, 크기 10 x 1)
  correct_class_score = scores[y]
  D = W.shape[0] # D : 클래스 수 (ex. CIFAR-10의 경우, 10)
  loss_i = 0.0
  for j in range(D): # 모든 오답 클래스에 대해 반복
    if j == y: # 오답 클래스에 대해서만 반복하므로, 정답 클래스에서는 스킵
      continue
    loss_i += max(0, scores[j] - correct_class_score + delta) # i번째 데이터에 대한 손실값을 누적
  return loss_i

def L_i_vectorized(x, y, W):
  """
  조금 더 빠른, 반만 벡터화한 버전.
  반만 벡터화했다는 말의 뜻은 하나의 데이터 (x, y)를 입력받지만(따라서 전체 데이터 셋에 대해 함수를 적용하려면 함수 외부에서 반복문을 사용해야 한다) 내부에서 반복문을 사용하지 않는다는 뜻이다.
  """
  delta = 1.0
  scores = W.dot(x)
  margins = np.maximum(0, scores - scores[y] + delta) # 한 번의 벡터 연산으로 전체 클래스들에 대한 점수를 구한다
  margins[y] = 0 # y번째 위치(정답 클래스)에서 scores[y] - scores[y]는 상쇄되고 델타만 남는다. 정답 클래스에서의 계산 결과는 필요없으므로(오답 클래스에서의 계산 결과만 필요하다) 값을 없앤다.
  loss_i = np.sum(margins)
  return loss_i

def L(X, y, W):
  """
  완전 벡터화된 버전
  - X : 데이터 셋의 모든 이미지를 나타내는 행렬. 하나의 열은 하나의 이미지를 의미한다. (ex. CIFAR-10의 경우, 크기 3073 x 50,000)
  - y : 정답 클래스의 인덱스를 나타내는 정수 배열 (ex. CIFAR-10의 경우, 50,000 차원의 배열)
  - W : 가중치 행렬 (ex. CIFAR-10의 경우, 크기 10 x 3073)
  """
  # 과제 : 반복문을 전혀 사용하지 않고 전체 데이터에 대한 손실값을 계산해야 함
{% endhighlight %}

학습 셋에 대해 좋은 예측을 한다는 것은 손실값을 최소화한다는 말과 같은 말이다.

> 이제 우리가 해야 할 것은 손실값을 최소화하는 가중치를 찾는 방법을 찾기만 하면 된다.

# Practical Considerations

## Setting Delta

우리는 하이퍼파라미터 $\Delta$와 그 값을 설정하는 방법에 대해 알아보았다. $\Delta$를 얼마로 설정해야 할까? 또 정말로 교차 검증법을 사용해야 할까? 사실 모든 경우에 $\Delta = 1$로 설정해도 안전하다는 것이 알려져 있다. $\Delta$와 $\lambda$는 서로 다른 두 개의 하이퍼파라미터로 보이겠지만, 사실 둘은 같은 trade-off를 조절한다. 이 둘은 손실 함수에서 데이터에 의한 손실값과 규제화에 의한 손실값 사이의 trade-off를 조절한다. $W$의 크기는 클래스 점수에 직접적인 영향을 끼친다(그리고 물론 클래스 점수들의 차이에도 영향을 끼친다). 만약 $W$ 안의 모든 가중치들을 줄인다면 각 클래스 점수들의 차이 역시 줄어들게 되고, $W$ 안의 모든 가중치들을 늘린다면 각 클래스 점수들의 차이 역스 늘어나게 된다. 따라서 어차피 가중치 값들이 클래스 점수 간 차이를 임의로 늘렸다 줄였다 할 수 있으므로 $\Delta$는 무의미하다고 볼 수 있다. 따라서, 진정으로 우리가 생각해야 하는 것은 규제화 강도 $\lambda$를 통해 가중치들을 얼마까지 커지게 허용할지 만이다.

## Relation to Binary Support Vector Machine

아마 이 수업에 들어오기 전 Binary Support Vector Machine(Binary SVM)을 다뤄본 경험이 있을 것이다. Binary Support Vector Machine에서 $C$는 하이파라미터, $y\_i \in \{ -1, 1 \}$라 할 때, i번째 데이터에 대한 손실값은 다음과 같이 된다.

$$L_i = C \max(0,\, 1 - y_i w^Tx_i) + R(W)$$

Binary SVM은 우리가 앞에서 배웠던 (Multiclass) SVM 손실 함수에서 클래스가 두 개밖에 없을 때의 특별한 경우이다. 또한 이 식에서의 $C$와 SVM 손실 함수에서의 $\lambda$는 같은 trade-off를 조절하는 값으로, 서로 $C \propto \frac {1}{\lambda}$의 관계가 있다.

# Softmax classifier

SVM은 가장 많이 보이는 두 분류기 중 하나이다. 나머지 하나는 **소프트맥스 분류기(Softmax classifier)**로, SVM과 다른 손실 함수를 사용한다. 소프트맥스 분류기는 이진 로지스틱 회귀 분류기(binary Logistic Regression classifier)를 여러 클래스에 대해 일반화한 것이라 할 수 있다. SVM에서는 점수 함수의 출력값 $f(x\_i, W)$을 각 클래스에 대한 점수로 다뤘다. 이 값은 보정되지 않았고(uncalibrated) 해석하기 어려웠다. 하지만 소프트맥스 분류기는 조금 더 직관적인 출력값을 낸다. 소프트맥스 분류기에서도 점수 함수 $f(x\_i;W) = Wx\_i$는 그대로 사용하나, 이 점수값을 각 클래스에 대한 정규화되지 않은 로그 확률(unnormalized log probability)로 해석한다. 또한 힌지 손실 함수(hinge loss)을 사용하는 대신 다음과 같이 생긴 **크로스 엔트로피 손실 함수(cross entropy loss)**을 사용한다. 

$\displaystyle L\_i = -\log \left( \frac { e^{f\_{y\_i}} } { \sum\_j e^{f\_j} } \right)$  또는  $\displaystyle L\_i = -f\_{y\_i} + \log \sum\_j e^{f\_j}$
{: .text-align-center}

이때 $f\_j%는 클래스 점수 벡터 $f$의 j번째 요소를 의미한다. 전과 같이, 데이터 셋에 대한 전체 손실값은 전체 학습 데이터에 대한 $L\_i$의 평균에 규제화 항 $R(W)$를 더한 것이다. 함수 $f\_j(z) = \frac{e^{z\_j}}{\sum\_k e^{z\_k}}$는 **소프트맥스 함수(Softmax function)**이라 부른다. 소프트맥스 함수는 임의의 실수 값 점수들로 이루어진 벡터($z$)를 입력받아 모든 요소를 0과 1 사이이고, 합이 1이 되도록 바꾼다. 소프트맥스 함수를 사용하는 전체 크로스 엔트로피 손실 함수를 처음 보면 조금 무서울 수 있지만, 사실 아주 간단하게 유도할 수 있다.

## Information theory view

"정답" 분포(distribution) $p$와 추정된 분포 $q$ 사이의 크로스 엔트로피는 다음과 같이 정의된다.

$$H(p, \, q) = - \sum _x p(x) \log q(x)$$

소프트맥스 분류기는 추정된 클래스 확률값들과(위에서 봤듯이, $q = e^{f\_{y\_i}}  / \sum\_j e^{f\_j}$) "정답" 분포 사이의 크로스 엔트로피를 최소화하려 한다. 이때 "정답" 분포는 $p = [0, \, \cdots,\, 1, \, \cdots, \, 0]$과 같이, 확률 질량(probability mass)가 정답 클래스에 쏠려 있는(= $y\_i$번째 요소만 1이고 나머지는 모두 0) 형태이다. 또한 크로스 엔트로피는 다음과 같이 엔트로피와 쿨백-라이블러 발산(Kullback-Leibler Divergence)에 관한 식으로 표현할 수 있다.

$$H(p,q) = H(p) + D_{KL}(p||q)$$

이때 델타 함수의 엔트로피 $p$는 0이므로 크로스 엔트로피를 최소화한다는 것은 두 분포 사이의 쿨백-라이블러 발산(= 두 벡터 간의 거리)을 최소화하는 것과 동일하다. 다시 말해, 크로스 엔트로피 손실 함수는 예측된 분포의 모든 확률 질량이 정답 클래스에 몰려 있기를 "원한다".

## Probabilistic interpretation

크로스 엔트로피 손실 함수의 식을 잘 보면 다음과 같은 부분이 있는 것을 볼 수 있다.

$$P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }$$

이 부분은 파라미터 $W$, 이미지 $x\_i$가 주어졌을 때, 정답 레이블 $y\_i$의 정규화된 확률값이라 해석할 수 있다. 소프트맥스 분류기가 출력 벡터 $f$ 안의 점수들을 정규화되지 않은 로그 확률값들로 해석한다는 것을 기억하자. 이 값들을 $e$의 지수로 올리면 따라서 (정규화되지 않은) 확률값들이 나오고, 이를 전체의 합으로 나누면 모든 확률값들의 합이 1이 되도록 정규화가 수행된다. 확률적으로 이를 해석하면, 소프트맥스 분류기는 정답 클래스에 대한 음의 로그 우도(negative log likelihood)를 최소화한다. 이는 최대 우도 추정(MLE, Max Likelihood Estimation)을 수행하는 것으로 해석할 수 있다. 이 관점의 장점은 MLE가 아닌 MAP(Maximum a posteriori)를 수행한다고 하면 전체 손실 함수 안의 규제화 항 $R(W)$를 가중치 행렬 $W$에 대한 Gaussian prior로부터 온 항이라 해석할 수 있다는 것이다.

## Practical issues : Numeric stability

실제로 소프트맥스 함수를 계산하기 위한 코드를 작성할 때, $e^{f\_{y\_i}}$와 $\sum \_j e^{f\_j}$는 거듭제곱 때문에 매우 커질 수 있다. 큰 수로 나누는 것은 계산 안정성이 낮기에 약간의 정규화 기법을 사용해야 한다. 분자와 분모에 상수 $C$를 곱한 후 식을 변형하면 다음을 얻을 수 있다.

$$\frac{e^{f_{y_i}}}{\sum_j e^{f_j}} = \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}} = \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}$$

$C$로 어떠한 값을 사용하든 결과는 바뀌지 않으므로, 아무 값이나 사용해도 된다. 따라서 계산 안정성을 높일 수 있는 적당한 $C$를 선택할 수 있다. 일반적으로는 $\log C = -\max\_j f\_j$가 되도록 $C$를 설정한다. 이렇게 하면 벡터 $f$ 안의 값들이 이동해 가장 큰 값이 0이 되도록 한다. 코드로는 다음과 같이 하면 된다.

{% highlight python %}
# 기존 방법
f = np.array([123, 456, 789]) # 3개의 클래스가 있고, 각 클래스 점수가 매우 큰 상황이라 해 보자.
p = np.exp(f) / np.sum(np.exp(f)) # BAD : 계산 과정에서 오버플로우 등이 일어날 수 있다.

# 계산 안정성을 높인 방법
f -= np.max(f) # f becomes [-666, -333, 0] # f의 요소의 값들을 최대값이 0이 되도록 옮긴다. f = [-666, -333, 0]이 되었다.
p = np.exp(f) / np.sum(np.exp(f)) # SAFE : 계산 과정에서 터지지 않고 정답을 잘 출력한다.
{% endhighlight %}

## Possibly confusing naming conventions

SVM 분류기는 힌지 손실 함수(max-margin 손실 함수라고도 한다)를 사용한다. 소프트맥스 분류기는 크로스 엔트로피 손실 함수를 사용한다. 소프트맥스 분류기는 소프트맥스 함수로부터 그 이름이 나왔는데, 소프트맥스 함수는 점수 함수로부터 출력된 클래스 점수들을 합이 1이 되게 정규화된 양수로 바꿔 크로스 엔트로피 손실 함수가 적용될 수 있게 만들어주는 역할을 한다. 사실 소프트맥스 함수는 단순히 클래스 점수값들을 뭉개기만 하므로 엄밀히 말해 "소프트맥스 손실 함수(softmax loss)"라는 표현은 말이 안되는 표현이지만, 사람들은 크로스 엔트로피 손실 함수를 줄여서 소프트맥스 손실 함수라 많이 부른다.

# SVM vs. Softmax

다음 그림을 보면 SVM 분류기와 소프트맥스 분류기 사이의 차이를 명확히 할 수 있을 것이다.

{% include caption-img.html src="https://cs231n.github.io/assets/svmvssoftmax.png" outside_img="true" description="데이터 하나에 대해 SVM 분류기와 소프트맥스 분류기가 적용될 때의 차이점 예제. 두 경우 모두 행렬곱 연산으로 계산된 같은 벡터 $f$를 사용한다. 차이점은 $f$ 안의 값들을 해석할 때 발생한다. SVM 분류기는 이 값들을 클래스 점수로 해석하고, SVM 분류기의 손실 함수는 정답 클래스(class 2, 파란색)의 점수가 다른 모든 오답 클래스의 점수보다 특정 값(margin) 이상 크게 만든다. 소프트맥스 분류기는 반면 이 값들을 각 클래스에 대한 (비정규화된) 로그 확률값(log probability)으로 해석하고, 소프트맥스 분류기의 손실 함수는 정답 클래스의 (정규화된) 로그 확률값이 커지게 만든다. 이 예제에서 SVM 분류기의 최종 손실값은 1.58이 나오고, 소프트맥스 분류기의 최종 손실값은 1.04가 나온다(밑으로 $e$를 사용해 계산한 값이다). 하지만 이 두 값은 서로 비교 불가능하다. 같은 데이터에 대해 같은 분류기로 계산한 손실값만이 서로 비교 가능하다." %}

## Softmax classifier provides "probabilities" for each class

SVM 분류기가 보정되지 않았고(uncalibrated) 해석하기 어려운 클래스 점수값을 계산하는 것과 다르게, 소프트맥스 분류기는 각 클래스에 대한 "확률(probability)"값을 계산하게 해 준다. 예를 들어, SVM 분류기는 [12.5, 0.6, -23.0]과 같이 주어진 이미지의 "고양이(cat)", "강아지(dog)", "배(ship)" 클래스 점수가 얼마인지 계산해 준다. 하지만 소프트맥스 분류기는 [0.9, 0.09, 0.01]과 같이 각 클래스에 대한 "확률값"을 계산해 줘, 분류기가 각 클래스에 대해 얼마나 확신하는지(confidence) 해석할 수 있게 해 준다. "확률값"에 따옴표를 친 이유는 이 확률값들의 분포가 모여있을지 펼쳐져 있을지는 사용자가 직접 입력해 주는 규제화 강도(regularization strength) $\lambda$값에 직접적으로 연관되어 있기 때문에 그렇다. 예를 들어, 어떤 3개의 클래스에 대해 정규화하지 않은 로그 확률값이 [1, -2, 0]으로 나왔다고 해 보자. 소프트맥스 분류기는 다음과 같이 주어진 값들에 지수 함수를 적용한 후 소프트맥스 함수를 적용할 것이다.

$[1, -2, 0]$ → $[e^1, e^{-2}, e^0] = [2.71, 0.14, 1]$ → $[0.7, 0.04, 0.26]$
{: .text-align-center }

만약 규제화 강도 $\lambda$ 값이 더 컸다면, 가중치 $W$는 더 크게 규제를 받아 작아졌을 것이다. 가중치들이 반으로 줄어 정규화하지 않은 로그 확률값으로 [0.5, -1, 0]이 나왔다고 해 보자. 소프트맥스 분류기는 다음과 같이 작동한다.

$[0.5, -1, 0]$ → $[e^{0.5}, e^{-1}, e^0] = [1.65, 0.37, 1]$ → $[0.55, 0.12, 0.33]$
{: .text-align-center }

확률값들은 더욱 더 펼쳐져 있게 되었다. 만약 아주 강한 규제화 강도 $\lambda$ 때문에 가중치들이 정말 작아졌다면, 출력되는 확률값들은 거의 평탄할(uniform) 것이다. 따라서, 소프트맥스 분류기에 의해 계산되는 확률값들은 사실은 확신도의 개념으로 이해하는 것이 좋다. SVM 분류기에서의 결과처럼, 각 값들의 순서 정도는 해석할 만해도, 절대적인 수치(혹은 그들 간의 차이)는 의미없는 값이다.

## In practice, SVM and Softmax are usually comparable

SVM 분류기와 소프트맥스 분류기 간의 성능 차이는 보통 매우 작고, 사람들마다 어느 분류기가 더 나은지에 대한 의견은 다를 것이다. 소프트맥스 분류기에 비해 SVM 분류기는 더 *지역적인(local)* 목표를 가지고 있는데, 이는 장점일 수도 있고 단점일 수도 있다. [10, -2, 3]의 클래스 점수를 얻었고, 첫 번째 클래스가 정답인 경우를 생각해 보자. $\Delta = 1$을 사용하는 SVM은 이를 보고 정답 클래스의 점수가 다른 모든 오답 클래스의 점수보다 $\Delta$ 이상 크므로 손실값으로 0을 계산할 것이다. SVM 분류기는 점수 각각에 대한 디테일에는 관심이 없다. 클래스 점수가 [10, -100, -100]이든 [10, 9, 9]이든 SVM 분류기는 $\Delta = 1$이므로 모두 동일하게 손실값으로 0을 계산한다. 그러나 소프트맥스 분류기에서는 그렇지 않다. 소프트맥스 분류기는 [10, -100, -100]보다 [10, 9, 9]에 더 큰 손실값을 계산할 것이다. 다시 말해, 정답 클래스는 언제나 조금 더 큰 확률값을 가질 수 있고, 오답 클래스는 언제나 조금 더 작은 확률값을 가질 수 있고, 손실값은 언제나 더 작아질 수 있으므로, 소프트맥스 분류기는 절대 점수에 완벽히 만족할 수 없다. 반면 SVM 분류기는 $\Delta$ 값만 충족되면 만족할 수 있고, 이 제약조건을 넘어서 점수값을 미세조정하지 않는다. 이는 장점이라 볼 수 있다. 예를 들어 자동차를 분류하는 SVM 분류기는 자동차와 트럭을 구분하는 것과 같이 더 어려운 문제에 모든 "노력"을 집중할 수 있다. 자동차와 개구리를 구분하는 것과 같은 문제에는, 개구리가 이미 아주 낮은 점수를 받았다면 더 이상 집중하지 않는다.

# Interactive web demo

[웹 데모](http://vision.stanford.edu/teaching/cs231n/linear-classify-demo)
{: .text-align-center }

{% include caption-img.html src="https://cs231n.github.io/assets/classifydemo.jpeg" outside_img="true" description="선형 분류기에 대한 이해를 도울 수 있는 반응형 웹 데모. 해당 데모에서는 3가지 클래스를 가지는 2차원 데이터에 대한 손실 함수를 시각화한다. 데모에서는 최적화(optimization)도 수행하는데, 이에 대해서는 다음 글에서 자세히 다루겠다." %}

# Summary

- 이미지 픽셀로부터 클래스 점수를 계산하는 **점수 함수(score function)**를 정의했다. 이 글에서는 가중치 $W$와 편향 $b$를 변수로 사용하는 선형 함수(linear function)을 사용했다.
- kNN 분류기와 다르게, 이 **매개 변수 기반 접근법(parametric approach)**에서는 파라미터 학습이 완료되면 학습 데이터를 폐기해도 된다. 또한 이 방법에서는 새로운 테스트 이미지에 대한 예측을 할 때 모든 테스트 이미지와의 비교를 할 필요 없이 $W$와의 단 한번의 행렬곱 연산만 하면 되므로 빠르다.
- 편향 벡터를 가중치 행렬 안으로 집어넣는 Bias trick에 대해 배웠다. Bias trick을 사용하면 하나의 파라미터 행렬만 들고 다니면 되므로 편리하다.
- 학습 데이터 셋에서 참값 레이블(ground truth labels)에 대해 주어진 파라미터들이 얼마나 잘 호환되는지를 측정하는 **손실 함수(loss function)**를 정의했다. 이 글에서는 선형 분류기에서 흔히 쓰이는 **SVM 손실 함수**와 **소프트맥스 손실 함수**에 대해 배웠다. 학습 데이터에 대해 좋은 예측을 했다는 것은 손실 함수가 작은 손실값을 가진다는 말과 동치이다.

우리는 이제 주어진 데이터 셋 안의 이미지들을 파라미터 값에 기반해 클래스 점수로 변환하는 방법과, 예측의 품질을 측정하는데 사용할 수 있는 두 가지 손실 함수에 대해 배웠다. 그렇다면 어떻게 하면 최고의(= 가장 작은) 손실값을 만드는 파라미터 값을 결정할 수 있을까? 이 과정을 최적화(optimization)이라 한다. 이에 관해서는 다음 문서에서 자세히 다룰 것이다.

# Further Reading

- [Deep Learning using Linear support Vector Machines](https://arxiv.org/abs/1306.0239), Charlie Tang, 2013
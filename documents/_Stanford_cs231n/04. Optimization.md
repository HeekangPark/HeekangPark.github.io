---
title: "최적화 (Optimization)"
order: 4
date_created: "2020-12-27"
date_modified: "2021-03-25"
---

[Optimization note](http://cs231n.github.io/optimization-1)

# Introduction

이전 섹션에서 우리는 이미지 분류 문제에 있어 중요한 두 가지 요소에 대해 배웠다.

1. 이미지의 픽셀 값들을 클래스 점수로 변환하는 (파라미터를 사용하는) **점수 함수(score function)** (ex. 선형 함수)
2. 특정 파라미터 값들이 학습 데이터에서 점수 함수가 계산한 클래스 점수가 실제 참값 레이블(ground truth label)과 얼마나 잘 맞게 하는지를 측정하는 **손실 함수(loss function)**. 소프트맥스 손실 함수, SVM 손실 함수 등 다양한 손실 함수가 존재한다.

구체적으로, 선형 함수는 다음과 같은 형태로 나타낼 수 있었다.

$$f(x_i, \, W) = Wx_i$$

또한 SVM 손실 함수는 다음과 같은 형태로 나타낼 수 있었다.

$$L = \frac{1}{N} \sum_i \sum_{j \neq y_i} \left[ \max(0, f(x_i; \, W)_j - f(x_i;\, W)_{y_i} + 1) \right] + \alpha R(W)$$

우리는 이미지 $x\_i$에 대한 예측값과 참값 레이블 $y\_i$가 잘 맞게 하는 파라미터 $W$는 아주 낮은 손실값($L$)이 나오게 한다는 것도 함께 살펴보았다. 이제부터는 이미지 분류 과제에서 중요한 세 번째 요소인 **최적화(Optimization)**에 대해서 알아보겠다. 최적화란 손실 함수의 값을 최소화하는 파라미터 $W$의 값을 찾는 과정을 뜻한다.

## Foreshadowing

위 세 가지 요소(점수 함수, 손실 함수, 최적화)가 어떻게 상호작용하는지를 이해한 후, 우리는 다시 첫 번째 요소(점수 함수)로 돌아가 이를 NN, CNN 등에서 사용하는, 선형 함수보다 훨씬 더 복잡한 형태로 확장할 것이다. 손실 함수와 최적화는 비교적 바뀌지 않을 것이다.

# Visualizing the loss function

본 수업에서 살펴보게 될 손실 함수들은 일반적으로 아주 고차원 공간에서 정의되기 때문에 시각화시키기 어렵다(예를 들어 CIFAR-10에서의 선형 분류기의 경우 10 × 3073 = 30,730개의 파라미터로 이루어진 가중치 행렬을 사용한다.) 그러나 고차원 공간을 직선(1차원) 또는 면(2차원)으로 잘라서 보면 선형 함수에 대한 몇몇 직관을 얻을 수 있다. 예를 들어 랜덤 가중치 행렬 $W$을 만든 후(고차원 공간 상에서 한 점으로 표현된다), 임의의 한 직선을 따라 움직이면서 손실 함수의 값을 기록할 수 있다. 조금 더 구체적으로 말하면, 특정 방향 벡터 $W\_1$에 대해, 여러 가지 $a$를 사용해 손실값 $L(W + a W\_1)$을 계산할 수 있다. 이렇게 하면 x축을 $a$로, y축을 $L(W + a W\_1)$으로 한 그래프를 만들 수 있다. 이 과정을 두 개의 방향 벡터 $W\_1$, $W\_2$에 대해, 여러 가지 $a$, $b$를 사용해 손실값 $L(W + a W\_1 + b W\_2)$를 계산할 수 있다. 그래프로는 x축을 $a$로, y축을 $b$로, $L(W + a W\_1 + b W\_2)$은 색깔로 표현하여 그릴 수 있다.

{% include caption-img.html src="https://cs231n.github.io/assets/svm_one.jpg" outside_img="true" description="Multiclass SVM 손실 함수(규제화 없음)에서, CIFAR-10의 이미지 하나에 대한 손실값 변화 모습(왼쪽, 가운데)과, 100개의 이미지에 대한 손실값 변화 모습(오른쪽). 왼쪽 : $a$만을 변화시킬 때 1차원 손실값. 가운데, 오른쪽 : 2차원 손실값. 파란색은 낮은 손실값을 의미하고, 빨간색은 높은 손실값을 의미한다. SVM 손실 함수에서의 부분 부분 선형적인 구조(piecewise-linear structure)를 잘 생각해보자. 오른쪽 이미지에서는 여러 장의 이미지들에 대한 손실값들이 평균되어 합쳐져 있으므로, 오른쪽 이미지에서의 그릇 모양은 (가운데 이미지와 같은) 여러 개의 부분 부분 선형적인 그릇(piecewise linear bowl) 모양들이 합쳐진 것이다." %}

SVM 손실 함수에서 부분 부분 선형적인 구조(piecewise-linear structure)가 있음은 수학적인 방법으로 보일 수 있다. $i$번째 이미지에 대해 SVM 손실 함수는 다음과 같이 생겼다.

$$L_i = \sum_{j \neq y_i} \left[ \max(0, \, w_j^{\intercal}x_i - w_{y_i}^{\intercal}x_i + 1) \right]$$

식을 보면 알 수 있듯이, 각 이미지에서의 데이터에 의한 손실값(data loss)은 $W$에 대한 선형함수(정확히는, 선형함수에 $max(0,\, -)$ 함수가 씌여 zero-thresholded된 값)의 합이다. 또한 $W$의 각 행($w\_j$) 앞에는 +가 붙기도($j$가 오답 클래스인 경우), -가 붙기도($j$가 정답 클래스인 경우) 한다. 예를 들어, 세 개의 1차원 점들과 세 개의 클래스를 가진 간단한 데이터 셋이 있다고 해 보자. 전체 SVM 손실 함수(규제화 없음)는 다음과 같이 된다.

$$L_0 = \max(0,\, w_1^{\intercal}x_0 - w_0^{\intercal}x_0 + 1) + \max(0,\, w_2^{\intercal}x_0 - w_0^{\intercal}x_0 + 1)$$

$$L_1 = \max(0,\, w_0^{\intercal}x_1 - w_1^{\intercal}x_1 + 1) + \max(0,\, w_2^{\intercal}x_1 - w_1^{\intercal}x_1 + 1)$$

$$L_2 = \max(0,\, w_0^{\intercal}x_2 - w_2^{\intercal}x_2 + 1) + \max(0,\, w_1^{\intercal}x_2 - w_2^{\intercal}x_2 + 1)$$

$$∴ L = (L_0 + L_1 + L_2)/3$$

데이터들은 모두 1차원이므로, $x\_i$와 $w\_j$는 하나의 수(스칼라)이다. $w\_0$를 예로 들면, 위 함수식에서 몇몇 항들은 $w\_0$에 대한 선형 함수이고 각각은 0에서 꺾인다. 이는 다음과 같이 시각화할 수 있다.

{% include caption-img.html src="https://cs231n.github.io/assets/svmbowl.png" outside_img="true" description="데이터에 의한 손실값을 1차원으로 나타낸 그림. x축은 하나의 가중치를 뜻하고, y축은 손실값을 뜻한다. 데이터에 의한 손실값은 특정 가중치에 대해 독립이거나 zero-threshold된 선형 함수인 여러 항들의 합이다. 전체 SVM 데이터 손실값은 이 모양의 30,730차원 버전이다." %}

SVM 손실 함수는 그릇 모양의 그래프에서 알 수 있듯이 볼록 함수(convex function)의 한 예이다. 점수 함수 $f$를 NN으로 확장시키면 손실 함수는 볼록함수가 아니게 되고, 위 시각화는 그릇 모양이 아닌, 올록볼록한 영역들이 복잡하게 나오게 된다.

### Non-differentiable loss functions

SVM 손실 함수 식을 잘 보면 max 연산에 의해 생기는 뾰족점(kink)이 있는 것을 볼 수 있다. 뾰족점에서는 그라디언트(gradient)가 정의되지 않기 때문에, 엄밀하게 말하면 SVM 손실 함수는 미분 불가능하다. 그러나 subgradient는 여전히 존재하고, 일반적으로 그라디언트를 대체해 많이 사용된다. 본 수업에서는 그라디언트와 subgradient라는 용어를 섞어 쓸 것이다.

# Optimization

손실 함수는 가중치들의 집합 $W$의 성능을 수치화할 수 있게 해 준다. 최적화의 목표는 손실 함수를 최소화하는 $W$를 찾는 것이다. 이제부터 천천히 손실 함수를 최적화하는 방법을 알아보자. 볼록 함수 최적화 관련 지식이 있는 사람이라면 이 섹션에서 볼록 함수인 SVM 손실 함수의 최적화를 위해 이런 노력을 하는 것이 조금 이상해 보일 수 있을 것이나, 우리의 최종 목표는 볼록 함수 최적화 관련 지식을 쉽게 사용할 수 없는 NN을 최적화하는 것이라는 것을 잊지 말자.

## Strategy #1 : A first very bad idea solution : Random Search

주어진 파라미터 $W$가 얼마나 좋은지를 평가하는 것은 아주 간단하므로, 첫 번째 (아주 나쁜) 아이디어는 단순히 다양한 랜덤 가중치 값들에 대해 어느 것이 가장 잘 작동하는지를 찾는 것이다. 이는 다음과 같이 코드로 작성할 수 있다.

{% highlight python %}
# X_train : 학습 데이터 행렬. 각 열은 하나의 이미지를 의미. ex. CIFAR-10의 경우, 크기 3073 x 50,000 행렬
# Y_train : 학습 데이터 레이블 배열. ex. CIFAR-10의 경우, 크기 50,000 1차원 배열
# L : 손실 함수의 성능을 평가하는 함수

bestloss = float("inf")
for num in range(1000):
  W = np.random.randn(10, 3073) * 0.0001 # 랜덤 파라미터 생성
  loss = L(X_train, Y_train, W) # 전체 학습 데이터에 대해 손실값을 구함
  if loss < bestloss: # 최고의(가장 작은) 손실값을 내는 경우를 찾음
    bestloss = loss
    bestW = W
  print(f"in attempt {num} the loss was {loss}, best {bestloss}")
{% endhighlight %}

{: .code-result .code-result-example}
{% highlight text %}
in attempt 0 the loss was 9.401632, best 9.401632
in attempt 1 the loss was 8.959668, best 8.959668
in attempt 2 the loss was 9.044034, best 8.959668
in attempt 3 the loss was 9.278948, best 8.959668
in attempt 4 the loss was 8.857370, best 8.857370
in attempt 5 the loss was 8.943151, best 8.857370
in attempt 6 the loss was 8.605604, best 8.605604
... (trunctated: continues for 1000 lines)
{% endhighlight %}

위 코드에서 우리는 다양한 랜덤 가중치 벡터 $W$를 시도해 보았고, 그중 몇몇은 다른 것들에 비해 성능이 좋았다. 이제 이렇게 찾은 $W$ 중 최고의 값을 사용해 테스트 셋에 대해 적용해본다.

{% highlight python %}
# X_test : 테스트 데이터 행렬. ex. CIFAR-10의 경우, 크기 3073 x 10000
# Y_test : 테스트 데이터 레이블 행렬. ex. CIFAR-10의 경우, 크기 10000 x 1
scores = bestW.dot(Xtest) # scores : 전체 테스트 데이터에 대한 클래스 점수. CIFAR-10의 경우, 크기 10 x 10000
Ytest_predict = np.argmax(scores, axis = 0) # 각 열에서 가장 큰 점수를 가지는 인덱스 탐색
print(np.mean(Ytest_predict == Ytest)) # 정확도(맞힌 예측의 비율) 계산
{% endhighlight %}

{: .code-result .code-result-example}
{% highlight text %}
0.1555
{% endhighlight %}

최고의 $W$를 사용한 결과 정확도는 15.5%가 나왔다. 완전 랜덤으로 클래스를 추정하는 것의 정확도가 10%인 것을 감안하면, 머리를 전혀 쓰지 않고 랜덤으로 탐색한 것 치고는 완전 나쁜 결과는 아니다.

### Core idea : iterative refinement

당연히 우리는 이것보다 더 잘할 수 있다. 핵심 아이디어는 바로, 최고의 가중치 집합 $W$를 찾는 것은 아주 어렵거나 때때로 불가능하지만($W$가 복잡한 전체 NN의 가중치를 가지고 있는 경우 등) 특정 가중치 집합 $W$를 조금 더 좋게 조정하는 문제는 아주 쉽다는 것이다. 다시 말해, 우리의 접근법은 랜덤한 $W$에서 시작하여 점진적으로 조금씩 좋아지도록 조정해 나가는 것이다.

> 우리의 전략은 랜덤한 가중치 집합에서 시작해 손실값이 작아지도록 점진적으로 조정해 나가는 것이다.

### Blindfolded hiker analogy

안대를 착용하고 높은 산에서 아래에 닿기 위해 하이킹하는 것을 상상하면 앞으로 나올 내용을 이해하는데 도움이 된다. CIFAR-10로 예를 들면, $W$의 차원인 10 × 3073 = 30,730차원의 높은 산에서 내려가는 것을 상상하는 것이다. 산의 매 지점의 해발고도는 손실값을 의미한다.

## Strategy #2 : Random Local Search

생각할 수 있는 첫 번째 전략은 (현재 상태에서) 무작위 방향으로 발을 뻗은 후, 만약 그게 내려가는 방향일 때만 한 걸음을 움직이는 것이다. 구체적으로, 랜덤한 $W$에서 시작한 후 랜덤 움직임(perturbation) $\delta W$를 만들어, 만약 약간 움직인 $W + \delta W$에서의 손실값이 작다면 업데이트를 수행하는 것이다. 이 과정을 코드로 작성하면 다음과 같이 된다.

{% highlight python %}
W = np.random.randn(10, 3073) * 0.001 # 랜덤 시작값 W 생성
bestloss = float("inf")
for i in range(1000):
  step_size = 0.0001
  Wtry = W + np.random.randn(10, 3073) * step_size
  loss = L(Xtr_cols, Ytr, Wtry)
  if loss < bestloss:
    W = Wtry
    bestloss = loss
  print(f"iter {i} loss is {bestloss}")
{% endhighlight %}

이전과 동일한 횟수반큼 반복하면(1,000회) 이 방법은 테스트 셋을 분류하는데 정확도 21.4%가 나온다. 이전 방법보다는 좋아졌지만, 여전히 낭비가 많고 계산 비용이 크다.

## Strategy #3 : Following the Gradient

이전 섹션에서 우리는 가중치-공간(weight-space)에서 더 좋은 가중치 벡터가 나오는 방향(= 더 적은 손실값이 나오는 방향)을 찾으려 했다. 그런데 랜덤으로 좋은 방향을 찾지 않아도 된다는 것이 알려져 있다. 우리는 수학적으로 가장 가파르게 감소하는 최고의 방향을 계산할 수 있다. 이 방향은 손실 함수의 **그라디언트(gradient)**와 관련이 있다. 우리의 하이킹 비유에서, 이 방법은 발로 산의 경사를 가늠한 후, 가장 가파른 방향으로 한 걸음 움직이는 것에 대충 비유할 수 있겠다.

1차원 함수에서 기울기는 우리가 관심있는 지점에서의 즉각적인 함수값 변화량을 의미한다. 그라디언트는 함수의 기울기의 일반화된 버전으로, 하나의 스칼라 값이 아닌 벡터를 입력받는다. 또한 그라디언트는 입력 공간에서의 각 차원에 대한 기울기 벡터(vector of slopes, **도함수(derivative)**라는 표현을 더 많이 사용한다)를 의미한다. 1차원 함수에서의 입력값에 대한 미분값(derivative)은 수학적으로 다음과 같이 표현된다.

$$\frac{df(x)}{dx} = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}$$

우리가 관심있는 함수가 스칼라 값이 아닌 벡터를 입력받는다면, 우리는 미분 대신 **편미분(partial derivative)**이라는 용어를 사용하고, 그라디언트는 간단히 각 차원에 대한 편미분들의 벡터가 된다.

# Computing the gradient

그라디언트를 계산하는 방법은 느리고 근사치를 구하는 방법이지만 쉬운 방법(**수치해석적 그라디언트(numerical gradient)**)과 빠르고 정확하지만 미적분학 지식이 필요하고 오류가 나기 쉬운 방법(**해석적 그라디언트(analytic gradient)**), 이렇게 2가지가 있다. 두 방법 모두 알아보자.

## Computing the gradient numerically with finite differences

위의 공식은 수치해석적으로 그라디언트를 구하는 방법을 알려준다. 함수 `f`와 벡터 `x`가 주어졌을 때 `x`에서의 `f`의 그라디언트를 구하는 일반화된 방법은 다음과 같다.

{% highlight python %}
def eval_numerical_gradient(f, x):
  """
  x에서 f의 수치해석적 그라디언트를 구하는 간단한 방법 구현
  - f : 단일 인자를 받는 함수
  - x : 그라디언트를 계산하고자 하는 점(numpy 배열)
  """

  fx = f(x) # x에서의 함수값을 계산
  grad = np.zeros(x.shape)
  h = 0.00001

  # x의 모든 인덱스에 대해 반복
  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
  while not it.finished:
    # x + h에서의 함수값 계산
    ix = it.multi_index
    old_value = x[ix]
    x[ix] = old_value + h # h만큼 증가
    fxh = f(x) # f(x + h) 계산
    x[ix] = old_value # 이전 값으로 다시 복구 (아주 중요!)

    # 편미분 계산
    grad[ix] = (fxh - fx) / h # 기울기 계산
    it.iternext() # 다음 차원으로 이동

  return grad
{% endhighlight %}

위의 그라디언트 공식을 사용해, 위 코드는 각 차원마다 작은 변화값 `h`를 주고 함수값이 얼마나 변했는지를 통해 손실 함수의 편미분을 계산한다. 변수 `grad`에 최종적으로 계산된 그라디언트가 저장되게 된다.

### Practical considerations

위 수학적인 공식에서 그라디언트는 $h$가 0으로 다가갈 때의 극한값으로 정의되어 있지만, 일반적으로 아주 작은 값(ex. 위 코드에서처럼, 1e-5)을 사용하는 것으로 충분하다. 수치계산적 문제를 피하려면 최대한 작은 값을 쓰는 것이 좋다. 또한 수치계산적 그라디언트를 계산할 때 **centered difference formula**($[f(x + h) - f(x - h)]/2h$)를 사용하는 것이 일반적으로 성능이 조금 더 좋다.

어떠한 함수의 어떠한 점에서의 그라디언트도 위 코드에서의 함수로 계산할 수 있다. 가중치 공간 안의 무작위 점에서의 CIFAR-10 손실 함수의 그라디언트를 계산해 보자.

{% highlight python %}
# 위 코드에서는 인자(이 경우, 가중치 벡터)를 하나만 받는 함수를 사용한다. 따라서 X_train과 Y_train을 합쳐야 한다.
def CIFAR10_loss_fun(W):
  return L(X_train, Y_train, W)

W = np.random.rand(10, 3073) * 0.001 # 랜덤 가중치 벡터
df = eval_numerical_gradient(CIFAR10_loss_fun, W) # 그라디언트 계산
{% endhighlight %}

그라디언트는 각 차원마다 손실 함수의 기울기를 알려주므로, 우리는 이를 이용해 다음과 같이 가중치를 업데이트할 수 있다.

{% highlight python %}
loss_original = CIFAR10_loss_fun(W) # 오리지널 손실값
print(f"original loss: {loss_original}")

# 다양한 스텝 크기에 따른 효과를 확인
for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:
  step_size = 10 ** step_size_log
  W_new = W - step_size * df # 새로운 가중치 계산
  loss_new = CIFAR10_loss_fun(W_new)
  print(f"for step size {step_size} new loss: {loss_new}")
{% endhighlight %}

{: .code-result .code-result-example}
{% highlight text %}
original loss: 2.200718
for step size 1.000000e-10 new loss: 2.200652
for step size 1.000000e-09 new loss: 2.200057
for step size 1.000000e-08 new loss: 2.194116
for step size 1.000000e-07 new loss: 2.135493
for step size 1.000000e-06 new loss: 1.647802
for step size 1.000000e-05 new loss: 2.844355
for step size 1.000000e-04 new loss: 25.558142
for step size 1.000000e-03 new loss: 254.086573
for step size 1.000000e-02 new loss: 2539.370888
for step size 1.000000e-01 new loss: 25392.214036
{% endhighlight %}

### Update in negative gradient direction

우리는 그라디언트의 값이 작아지는 것을 원하므로, 위 코드에서 `W_new`를 계산할 때 그라디언트 `df`의 반대 방향(negative direction)으로 업데이트를 진행하고 있음을 볼 수 있다. 

### Effect of step size

그라디언트는 어떤 방향으로 갈 때 함수값이 가장 가파르게 증가하는지는 알려주지만, 해당 방향으로 얼만큼 가야 할지는 알려주지 않는다. 나중에 배우겠지만, 스텝의 크기(step size, *학습률(learning rate)*이라고도 한다)를 결정하는 것은 NN을 학습시킬 때 가장 중요한(그리고 가장 머리아픈) 하이퍼파라미터 설정값 중 하나이다. 위에서의 눈을 가린채로 산을 내려가는 비유에서, 발로 어느 방향이 가장 가파른지는 알아냈지만, 발걸음의 크기는 얼마여야 하는지는 알지 못하는 상황인 것이다. 발을 조심스럽게 내딛으면(작은 스텝 크기를 사용하는 상황) 계속 내려갈 순 있겠지만 아주 작은 양밖에 못 내려갈 것이다. 반대로 발을 크게, 확신에 차서 내딛으면 더 빨리 내려갈 순 있으나, 댓가가 발생한다. 위 코드에서 볼 수 있듯이, 스텝의 크기가 *너무 과하면(overstep)* 손실값이 커진다.

{% include caption-img.html src="https://cs231n.github.io/assets/stepsize.jpg" outside_img="true" description="스텝 크기에 의한 효과를 시각화한 자료. 우리는 특정 지점 W에서 시작하여 어느 방향이 가장 가파르게 감소하는 방향인지 알려주는 그라디언트를 계산할 것이다. 작은 스텝 크기는 계속 내려갈 수는 있지만 그 속도가 느리다. 큰 스텝 크기는 더 빠르게 내려갈 수 있지만 위험부담이 크다. 큰 스텝 크기를 사용하면 결국에는 목표보다 더 가고 손실값이 더 안좋아지게(더 커지게) 된다. 스텝의 크기(나중에는 <b>학습률(learning rate)</b>이라 부른다)는 조심스럽게 조정해야 하는, 가장 중요한 하이퍼파라미터 중 하나가 된다." %}

### A problem of efficiency

수치해석적인 방법으로 그라디언트를 계산하는 것은 파라미터 수에 비례하는 복잡도를 갖는다. 예시에서는 총 30,730개의 파라미터를 사용하므로 단 한번의 파라미터 업데이트를 위해서는 손실 함수에서 30,731번의 그라디언트 계산이 이루어져야 한다. 오늘날의 NN은 수천만개의 파리미터는 가뿐히 사용하므로 이 문제는 더욱 악회되고 있다. 이 방법은 명백히 확장 가능하지 않고, 우리는 더 좋은 방법이 필요하다.

## Computing the gradient analytically with Calculus

수치해석적 그라디언트는 유한차분법(finite difference approximation)를 사용하는 것으로 간단히 계산할 수 있지만 이는 근사치이고(실제 그라디언트에서는 h가 0으로 수렴할 때의 극한으로 정의되지만, 우리는 그냥 적당히 작은 수를 사용하고 있다) 계산 비용이 많이 든다. 그라디언트를 계산하는 두 번째 방법은 미적분학을 이용해 해석적으로 계산하는 것이다. 이 방법은 근사값이 아닌, 계산 속도가 아주 빠른, 정확한 그라디언트 수식을 얻게 해 준다. 그러나 수치해석적 그라디언트에 비해 해석적 그라디언트는 구현 과정에서 오류가 발생하기 쉽다. 그래서 많은 경우 구현의 정확도를 확인하기 위해 해석적 방법으로 계산한 그라디언트와 수치해석적 방법으로 계산한 그라디언트값을 비교하곤 한다. 이 방법을 **그라디언트 검사(gradient check)**라 한다.

특정 데이터 하나에 대한 SVM 손실 함수 식으로 예를 들어보자.

$$L_i = \sum_{j \neq y_i} \left[ \max(0, \, w_j^{\intercal} x_i - w_{y_i}^{\intercal} x_i + \Delta) \right]$$

가중치에 대해 이 식을 미분할 수 있다. 예를 들어, $1$을 괄호 안의 조건이 참이면 1, 거짓이면 0을 반환하는 지시 함수(indicator function)이라 하면, $w\_{y\_i}$에 대해 그라디언트를 구하면 다음과 같다.

$$\nabla_{w_{y_i}} L_i = - \left( \sum_{j \neq y_i} \mathbb{1}(w_j^{\intercal}x_i - w_{y_i}^{\intercal}x_i + \Delta > 0) \right) x_i$$

식을 이렇게 써 놓으니 조금 무서워 보일 수도 있지만, 이 수식을 코드로 구현할 때는 단순히 $\Delta$ 조건을 만족하지 못한(그래서 손실값의 증가에 기여한) 클래스들의 수를 센 후, 데이터 벡터 $x\_i$에 그 수를 곱하면 그게 바로 그라디언트이다. 참고로 이는 정답 클래스에 해당하는 $W$의 행에 대한 그라디언트이다. $j \neq y\_i$인 행들의 그라디언트는 다음과 같다.

$$\nabla_{w_j} L_i = \mathbb{1}(w_j^{\intercal}x_i - w_{y_i}^{\intercal}x_i + \Delta > 0) x_i$$

그라디언트의 식을 계산한 후에는 이를 코드로 바로 구현해 그라디언트 업데이트에 이 식을 쓰면 된다.

# Gradient Descent

이제 우리는 손실 함수의 그라디언트를 계산할 수 있게 되었다. 그라디언트를 계산해 파라미터 업데이트를 계속 수행하는 과정을 *경사하강법(Gradient Descent)*이라 한다. 이를 간단히 코드로 나타내면 다음과 같다.

{% highlight python %}
# 뼈대만 구현한 경사하강법

while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # 파라미터 업데이트 수행
{% endhighlight %}

이 간단힌 반복문이 모든 NN 라이브러리의 핵심이다. LBFGS와 같이 최적화를 수행하는 다른 방법도 존재한다만, 경사하강법은 현재로선 NN의 손실 함수를 최적화하는 가장 흔하고 인정받는 방법이다. 다음 단계로 나아가며 우리는 이 반복문에 부가기능(ex. 업데이트 식의 정확한 내용) 등을 넣을 것이지만, 결과값에 만족할 때까지 그라디언트를 따라가는 이 핵심 아이디어는 계속 같게 남아있을 것이다.

## Mini-batch gradient descent

아주 큰 문제(이를테면 ILSVRC 챌린지 등)에서 학습 셋은 수백만 개의 데이터로 구성되어 있을 수도 있다. 따라서 단 한번의 파라미터 업데이트를 위해 전체 학습 셋에 대해 손실값을 계산하는 것은 낭비가 심하다. 이 문제를 해결하는 대중적인 접근법은 학습 데이터의 **배치(batch)**마다 그라디언트를 계산하는 것이다. 예를 들어 현재 가장 최고 성능의 ConvNet에서는 한 배치에 전체 120만개의 학습 데이터 중 256개의 데이터가 포함된다. 이 배치는 파라미터를 한 번 업데이트하는데 사용된다.

{% highlight python %}
# 뼈대만 구현한 미니배치 경사하강법

while True:
  data_batch = sample_training_data(data, 256) # 256개의 데이터만 샘플링
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # 파라미터 업데이트 수행
{% endhighlight %}

이 방법이 잘 먹히는 이유는 학습 셋 안의 데이터들이 서로 상관(correlated)되어 있기 때문이다. 이를 보려면 ILSVRC의 전체 120만개의 이미지들이 사실은 1,000개의 이미지들이 중복되어 있는(즉 각 이미지마다 1,200개의 동일한 이미지가 있는 것) 극한의 상황을 상상해 보자. 그렇다면 1,200개의 복제본들에 대해 그라디언트를 계산한 것은 모두 같을 것이고, 전체 120만개 이미지에 대해 데이터에 의한 손실값을 평균하면 1,000개의 부분집합에 대해 계산한 손실값과 동일한 값이 나올 것이다. 물론 실제로는 데이터 셋은 중복 이미지를 가지고 있지 않을 것이지만, 미니 배치에서의 그라디언트는 전체 손실값의 그라디언트에 대한 좋은 근사값이 된다. 따라서 미니 배치 그라디언트를 계산하여 더 자주 파라미터 업데이트를 수행하면 (손실 함수를) 더 빨리 수렴(convergence)시킬 수(= 최적화할 수, 최소화할 수) 있다.

이를 극단화하면 미니 배치 하나에 오직 하나의 데이터만 넣은 것이 된다. 이를 **확률적 경사 하강법(SGD, Stochastic Gradient Descent)**(또는 on-line 경사하강법(on-line gradient descent))이라 한다. 그러나 코드를 벡터화하여 최적화하면 100개의 데이터에 대해 그라디언트를 계산하는 것이 데이터 하나에 대해 그라디언트를 계산하는 것을 100번 반복하는 것보다 더 효율적이기 때문에 확률적 경사 하강법은 비교적 덜 사용된다. SGD가 그라디언트를 계산할 때 한 번에 하나의 데이터만을 사용하는 것을 뜻하지만, 몇몇 사람들은 미니배치 경사하강법을 SGD라 부르기도 한다(미니배치 경사하강법을 "MGD"로, 배치 경사하강법을 "BGD"로 부르는 것은 잘 보기 힘들다). 미니 배치의 크기는 하이퍼파라미터의 일종이지만 일반적으로 교차 검증법을 잘 적용하지 않는다. 일반적으로 미니 배치의 크기는 (만약 메모리 크기에 제한이 있다면) 메모리 크기에 기반하여 결정되거나, 32, 64, 128과 같은 적당한 값으로 설정된다. 많은 벡터 연산 구현체(vectorized operation implementation)에서 입력값의 크기가 2의 거듭제곱일 때 더 빨리 작동하므로 우리는 미니배치의 크기로 2의 거듭제곱을 사용하겠다.

# Summary

{% include caption-img.html src="https://cs231n.github.io/assets/dataflow.jpeg" outside_img="true" description="전체 과정에 대한 요약. (x, y) 순서쌍들의 데이터 셋이 주어졌다고 하자. 데이터 셋의 값은 변경할 수 없다. 가중치는 랜덤한 값에서 시작하고, 바뀔 수 있다. 순전파(forward pass) 시 점수 함수(score function)는 클래스 점수(class score)를 계산하고 이를 벡터 f에 저장한다. 손실 함수(loss function)는 점수 f와 참값 레이블 y 간 일치도를 계산한 데이터로부터의 손실값(data loss)과, 가중치에 대한 함수인 규제화에 의한 손실값(regularization loss), 이렇게 두 개의 요소로 구성된다. 경사하강법(gradient descent)을 수행할 때 우리는 가중치의 그라디언트를 계산한 후(원한다면 데이터에 대한 그라디언트를 계산할 수도 있다) 파라미터를 업데이트할 때 그 값을 사용한다." %}

- 손실 함수는 **고차원의 최적화해야 할 대상(high-dimensional optimization landscape)**이고, 눈을 가린 등산객이 여기에서 바닥에 닿으려 하는 것이라는 비유를 만들었다. 또한 SVM 손실 함수가 부분 부분 선형적이고(piece-wise linear) 그릇 모양으로 생겼다는 것도 보았다.
- 손실 함수를 **점진적으로 개선해(iterative refinement)** 최적화한다는 아이디어를 만들었다. 즉 랜덤한 가중치 집합에서 시작해 손실값이 최소화될 때까지 단계별로 이를 개선해 나가는 것이다.
- 함수의 **그라디언트(gradient)**는 함수값이 가장 가파르게 올라가는 방향을 알려준다는 것을 보았고, 유한차분법(finite difference approximation)을 이용해 수치해석적으로 그라디언트를 계산하는 간단하지만 비효율적인 방법을 논의했다(여기서 유한차분(finite difference)은 h값이 된다).
- 파리미터 업데이트에는 **스탭 크기(step size)** 혹은 **학습률(learning rate)**이라 불리는 하이퍼파라미터가 반드시 잘 설정되어야 한다는 것을 보았다. 만약 이 값이 너무 낮다면 맞는 방향으로 계속 나아는 가지만 너무 느릴 것이다. 만약 이 값이 너무 크다면 속도는 빠를 것이나 위험부담이 커질 것이다. 이후 섹션에서 둘 사이의 tradeoff에 대해 조금 더 자세히 살펴볼 것이다.
- **수치해석적 그라디언트(numerical gradient)**와 **해석적 그라디언트(analytic gradient)**를 계산하는 것 사이의 장단점에 대해 논하였다. 수치해석적 그라디언트는 간단하지만 근사치이고 계산 비용이 많이 든다. 해석적 그라디언트는 정확하고 계산 속도가 빠르지만 수학을 이용해 그라디언트를 미분해야 하기 때문에 오류가 나기 쉽다. 따라서 실전에서는 반드시 해석적 그라디언트를 사용하고, 수치해석적 그라디언트로 계산된 값과 비교하는 **그라디언트 검사(gradient check)**를 수행해야 한다.
- 반복문 안에서 반복적으로 그라디언트를 계산하고 파라미터를 업데이트하는 **경사하강법(gradient descent)** 알고리즘에 대해 배웠다.

## Coming up

이 섹션에서 가장 중요한 점은 손실 함수에서 가중치에 대한 그라디언트를 계산하는 능력, 그리고 그라디언트에 대한 직관적인 이해이다. 이는 NN을 디자인하고, 학습시키고 이해하는데 가장 중요한 기술이다. 다음 섹션에서는 **역전파(backpropagation)**라 불리는, 체인 룰(chain rule)을 이용해 그라디언트를 해석적으로 계산하는 방법을 배울 것이다. 이 방법을 이용하면 CNN을 포함한 거의 모든 종류의 NN의 손실 함수도 최적화시킬 수 있다.
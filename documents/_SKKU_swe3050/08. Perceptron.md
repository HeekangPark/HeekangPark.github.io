---
title: "퍼셉트론(Perceptron)"
order: 8
date_created: "2020-05-11"
date_modified: "2021-11-04"
---

[단순분류 문서](/swe3050/07-simple-classification)에서 사용한 모델



$$f(\boldsymbol{x}) = \mathrm{sign}(\boldsymbol{w}^T \boldsymbol{x})$$



를 퍼셉트론(Perceptron)이라 한다. 이번 글에서는 퍼셉트론에 대해 알아보자.

# 퍼셉트론 (Perceptron)

퍼셉트론은 1957년 프랑크 로젠블라트(Frank Rosenblatt)라는 사람에 의해 고안되었다.

퍼셉트론은 신경 세포(뉴런, neuron)의 동작을 모방하여 만들어졌다. 신경 세포는 가지 돌기(dendrite)로부터 신호를 받아들여, 그 총합이 특정 값(역치, threshold) 이상일 경우 활성화(activate)되어 축삭 돌기 말단(axon terminal)으로 신호를 전달한다.

{% include caption-img.html src="perceptron-neuron.png" title="Fig.01 신경 세포와 퍼셉트론" description="왼쪽은 신경 세포를, 오른쪽은 퍼셉트론을 도식화한 것이다.<br/>신경 세포에서 머리 부분(왼쪽)의 가지처럼 뻗어 나온 것이 가지 돌기(dendrite)이고, 꼬리 부분(오른쪽)이 축삭 돌기 말단(axon terminal)이다.<br/>퍼셉트론에서 왼쪽 반원이 선형 결합기(linear combiner)이고, 오른쪽 반원이 하드 리미터(hard limiter)이다." %}

퍼셉트론은 두 가지 요소로 구성된다.

- 선형 결합기(linear combiner) : 입력의 가중합(weighted sum)을 계산한다. 가중합이란 입력($x$)들을 더할 때 각각에 가중치($w$)를 곱하여 더한다는 뜻이다.
- 하드 리미터(hard limiter) : 선형 결합기로부터의 출력값이 임계값(threshold)를 넘으면 +1, 넘지 못하면 -1을 출력한다.

퍼셉트론을 나타낸 식 $f(\boldsymbol{x}) = \mathrm{sign}(\boldsymbol{w}^T \boldsymbol{x})$에서, $\boldsymbol{w}^T \boldsymbol{x}$ 부분이 선형 결합기이고, $\mathrm{sign}$ 부분이 하드 리미터이다. $\mathrm{sign}$ 하드 리미터의 임계값은 0이다.

퍼셉트론은 입력을 분류하기 위해 사용된다. 퍼셉트론은 입력 데이터를 "출력 결과로 (+1)이 나오는 집합"와 "(-1)이 나오는 집합", 이렇게 두 개의 집합(class)으로 분류한다. 이때 분류는 선형적인 연산을 통해 이뤄진다. 퍼셉트론의 선형 결합기가 선형 연산을 수행하고, 하드 리미터가 그 값이 양수인지 음수인지 분류를 수행하는 것이다. 이를 기하학적으로 생각하면, 퍼셉트론은 $n$차원의 입력 공간(input space)을 두 개의 영역(클래스)으로 나누는 초평면(hyperplane)을 나타낸다고 할 수 있다. 그리고 퍼셉트론을 학습시킨다는 것은 바로 그 초평면을 찾는 과정이라 이해할 수 있다.

# 퍼셉트론 학습 알고리즘 (PLA, Perceptron Learning Algorithm)

퍼셉트론은 퍼셉트론 학습 알고리즘(PLA, Perceptron Learning Algorithm)을 통해 학습시킬 수 있다. 퍼셉트론 학습 알고리즘은 경사 하강법을 이용하여 퍼셉트론 모델의 파라미터인 가중치($\boldsymbol{w})$의 최적화를 수행한다.

입력 데이터 $\boldsymbol{x}$와 출력 데이터(레이블) $y$가 주어졌고, 가중치 $\boldsymbol{w}$를 파라미터로 갖는 퍼셉트론 모델 $f(\boldsymbol{x}) = \mathrm{sign}(\boldsymbol{w}^T \boldsymbol{x})$을 해당 데이터에 대해 학습시키려 하는 상황을 생각해 보자. 모델이 데이터를 얼마나 잘못 분류하는지를 나타내는 오차 함수 $J(\boldsymbol{w})$가 주어졌을 때, 퍼셉트론 학습 알고리즘은 다음과 같은 순서로 작동한다.

1. $\boldsymbol{w}$를 무작위 값으로 초기화한다.
2. 현재의 $\boldsymbol{w}$에 대해 $J(\boldsymbol{w})$를 계산한다. 즉, 현재 모델이 데이터를 얼마나 잘못 분류하는지를 오차를 계산한다.
3. 경사 하강법을 이용하여 파라미터를 업데이트한다 : $\boldsymbol{w}\_{new} = \boldsymbol{w}\_{old} - \eta \nabla J(\boldsymbol{w}_{old})$
4. 2~3 과정을 잘못 분류된 데이터가 없어질 때까지(= $J(\boldsymbol{w})$가 0이 될 때까지 = 최적화 될 때까지) 수행한다.

# XOR 문제

상술했다시피 퍼셉트론은 선형적 연산을 통해 데이터를 분류한다. 데이터가 선형적으로 분리가 가능하다면(linearly separable), 퍼셉트론은 데이터를 잘 분류할 수 있다.

다음 데이터를 봐 보자.

<div class="table-wrapper" markdown="block">

| $x_1$ | $x_2$ | OR($x_1$, $x_2$) |
| :---: | :---: | :--------------: |
|   0   |   0   |        -1        |
|   0   |   1   |        1         |
|   1   |   0   |        1         |
|   1   |   1   |        1         |

</div>

<div class="table-wrapper" markdown="block">

| $x_1$ | $x_2$ | AND($x_1$, $x_2$) |
| :---: | :---: | :---------------: |
|   0   |   0   |        -1         |
|   0   |   1   |        -1         |
|   1   |   0   |        -1         |
|   1   |   1   |         1         |

</div>

{% include caption-img.html src="perceptron-or-and.png" title="Fig.02 OR GATE, AND GATE" description="왼쪽 그래프는 OR GATE을, 오른쪽 그래프는 AND GATE을 나타낸다. 빨간 선은 이들 데이터를 분류하는 퍼셉트론을 나타낸다." %}

AND GATE와 OR GATE는 그래프에서 확인할 수 있듯이 선형 분리가능(linearly separable)하다. 이 말은, 퍼셉트론을 학습시키면 AND GATE와 OR GATE 역할을 하게 할 수 있다는 것이다. 실제로 위 데이터에 대해 퍼셉트론을 학습시키면, 아주 잘 작동하는 AND GATE와 OR GATE를 얻을 수 있다. [이전 글]({{ site.url }}{{ site.baseurl}}/swe3050/05-simple-classification/)에서도 아주 잘 작동하는 퍼셉트론의 예를 볼 수 있다. 이런 성공적인 결과를 보고 사람들은 퍼셉트론에 많은 기대를 가졌다.

하지만 다음 데이터를 보자.

<div class="table-wrapper" markdown="block">

| $x_1$ | $x_2$ | XOR($x_1$, $x_2$) |
| :---: | :---: | :---------------: |
|   0   |   0   |        -1         |
|   0   |   1   |         1         |
|   1   |   0   |         1         |
|   1   |   1   |        -1         |

</div>

{% include caption-img.html src="perceptron-xor.png" title="Fig.03 XOR GATE" description="XOR 연산 데이터는 선형적으로 분류가 불가능하다." %}

XOR GATE는 선형 분리가능하지 않다. 이 말은, 퍼셉트론에게 XOR GATE를 학습시킬 수 없다는 뜻이다. XOR GATE뿐만 아니라, 선형 분리가능하지 않은 데이터는 퍼셉트론으로 분류할 수 없다. 그리고 대부분의 데이터들은 선형 분리가능하지 않다.

퍼셉트론이 간단한 XOR GATE마저도 학습할 수 없다는 사실이 알려지자 많은 사람들이 낙담했다. 사실 선형 분리가능하지 않는 데이터들을 분류하기 위해서는 단층 퍼셉트론(single-layer perceptron)이 아닌 여러 층의 퍼셉트론(multi-layer perceptron)이 필요하다. 하지만 당시엔 이 사실이 알려지지 않았었다. 그 결과 전문가 시스템(Expert System)이 등장하기 전까지 한동안 기계학습과 인공지능 분야에 지원이 뚝 끊기게 되었다. 이 시기를 인공지능의 첫 번째 겨울이라 한다.


# 퍼셉트론과 인공 신경(Artificial Neuron)과의 차이

인공 신경망(ANN, Artificial Neural Network)에서 사용되는 인공 신경과 퍼셉트론은 거의 유사하다. 일반적으로 퍼셉트론을 인공 신경의 전신이라고 본다.

굳이 한 가지 차이점을 꼽자면, 퍼셉트론은 -1 또는 1로 양자화된 출력만 내놓는 하드 리미터를 사용할 때, 인공 신경은 0에서 1 사이의 실수를 출력으로 내놓는 소프트 리미터(ex. 시그모이드)를 주로 사용한다.

인공 신경 역시 단독으로 사용되면 XOR GATE와 같은 선형 분리가능하지 않은 데이터를 분류할 수 없다. 하지만 인공 신경망은 여러 층의 인공 신경을 사용함으로서 선형 분리가능하지 않은 데이터도 분류 가능하게 할 수 있다.

<style>
.table-wrapper {
    overflow-x: auto;
    overflow-y: auto;
    max-height: 30em;
}

.table-wrapper.no-max-height {
    max-height: none;
}

.table-wrapper table {
    border-collapse: separate;
    border-spacing: 0;
    border-top: 1px solid #888888;
    overflow-x: auto;
    margin-left: auto;
    margin-right: auto;
}

.table-wrapper table th {
    background-color: #dde3ee;
}

.table-wrapper table th,
.table-wrapper table td {
    padding-top: 0.5em;
    padding-bottom: 0.5em;
    padding-left: 1em;
    padding-right: 1em;

    border-bottom: 1px solid #888888;
}

.table-wrapper table > tbody tr:nth-child(even) td {
    background-color: #eef1f7;
}

.table-wrapper table > tbody tr:nth-child(odd) td {
    background-color: #ffffff;
}
</style>
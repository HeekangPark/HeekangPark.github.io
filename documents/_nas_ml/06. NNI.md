---
title: "NNI"
order: 6
date: "2020-10-12"
---

[NNI](https://github.com/microsoft/nni)는 Feature Engineering, Neural Architecture Search(NAS), Hyperparameter Tuning, Model Compression 등의 자동화에 사용할 수 있는, 마이크로소프트에서 만든 가볍고 강력한 툴킷이다. 2020년 10월 현재 1.8버전이 최신 버전이다.

NNI를 이용하면 AutoML 실험에서 하이퍼파라미터를 가져오고, 실험(trial)을 돌리고, 결과를 확인하고, 다시 하이퍼파라미터를 조정하는 반복적인 과정을 자동적으로 수행해 주고, 그 결과값을 Web UI에서 편하게 확인할 수 있다.

# 설치

Ubuntu 18.04.4 LTS 환경[^1]에 NNI를 설치해 보자.

[^1]: Ubuntu >= 16.04, macOS >= 10.14.1, Windows 10 >=1809, python 64-bit >= 3.6 환경에 설치 가능하다.

우선 파이썬 가상환경을 만들고 활성화해야 한다.

{% highlight bash %}
$ conda create -n nni python=3.7
$ conda activate nni
{% endhighlight %}

이후 `pip`을 이용해 `nni` 패키지를 설치한다.

{% highlight bash %}
$ pip install nni
{% endhighlight %}

설치가 완료되면 명령줄에서 `nnictl` 명령어를 사용할 수 있게 된다. 다음 명령어로 설치된 NNI 버전을 확인할 수 있다.

{% highlight bash %}
$ nnictl -v
{% endhighlight %}

## 설치 검증

설치가 제대로 되었는지 확인해 보기 위해서 간단한 예제(MNIST)를 돌려보자. 이 예제를 실행하려면 TensorFlow 1.x가 설치되어 있어야 한다.[^2]

[^2]: python 3.8 이상부터는 TensorFlow 1.x 버전이 지원되지 않으므로 python 3.7 버전을 사용하자.

{% highlight bash %}
$ pip install tensorflow-gpu==1.15
{% endhighlight %}

git 저장소를 복제하여 예제를 다운받자.

{% highlight bash %}
$ git clone -b v1.8 https://github.com/Microsoft/nni.git
{% endhighlight %}

이후 다음 명령어를 실행한다.

{% highlight bash %}
$ nnictl create --config nni/examples/trials/mnist-tfv1/config.yml
{% endhighlight %}

위 명령어를 실행하면 MNIST 데이터 셋에 대해 최적의 모델을 찾는 실험이 실행된다. 다음과 같이 `INFO:  Successfully started experiment!`[^3]가 뜨면 성공적으로 설치가 완료된 것이다.

[^3]: 친절하게 초록색으로 하이라이트되어 나온다.

{% highlight text %}
INFO:  expand searchSpacePath: search_space.json to /home/heekang/workspoace/nni/examples/trials/mnist-tfv1/search_space.json 
INFO:  expand codeDir: . to /home/heekang/workspoace/nni/examples/trials/mnist-tfv1/. 
INFO:  Starting restful server...
INFO:  Successfully started Restful server!
INFO:  Setting local config...
INFO:  Successfully set local config!
INFO:  Starting experiment...
INFO:  Successfully started experiment!
------------------------------------------------------------------------------------
The experiment id is Wbh9tbfB
The Web UI urls are: http://127.0.0.1:8080   http://172.30.10.112:8080   http://147.46.15.21:8080   http://172.30.100.112:8080   http://172.17.0.1:8080
------------------------------------------------------------------------------------

You can use these commands to get more information about the experiment
------------------------------------------------------------------------------------
         commands                       description
1. nnictl experiment show        show the information of experiments
2. nnictl trial ls               list all of trial jobs
3. nnictl top                    monitor the status of running experiments
4. nnictl log stderr             show stderr log content
5. nnictl log stdout             show stdout log content
6. nnictl stop                   stop an experiment
7. nnictl trial kill             kill a trial job by id
8. nnictl --help                 get help information about nnictl
------------------------------------------------------------------------------------
{% endhighlight %}

`http://127.0.0.1:8080`으로 접속하면 실험 진행 과정 및 결과를 웹 UI로 편리하게 볼 수 있다.

다음 명령어를 입력해서 실험을 종료하자.

{% highlight bash %}
$ nnictl stop
{% endhighlight %}

# nnictl 명령어 자동완성 기능 활성화히기

`pip`을 이용해 NNI를 설치하였다면 기본적으로 자동완성 기능을 사용할 수 없는 상태로 설치된다. 자동완성 기능을 활성화해보자.

우선 `bash-complete`를 다운받는다.

{% highlight bash %}
$ wget https://raw.githubusercontent.com/microsoft/nni/<nni-version>/tools/bash-completion
{% endhighlight %}

- `<nni-version>` : NNI 버전. ex. `v1.8`, `master`

다운받은 `bash-complete`를 설치한다.

{% highlight bash %}
$ mkdir -p ~/.bash_completion.d
$ install -m644 bash-completion ~/.bash_completion.d/nnictl
$ echo '[[ -f ~/.bash_completion.d/nnictl ]] && source ~/.bash_completion.d/nnictl' >> ~/.bash_completion
{% endhighlight %}

터미널을 닫았다 다시 열자. 그럼 이제 `nnictl` 명령어에 자동완성을 사용할 수 있다.

자동완성 기능을 제거하고 싶다면 `~/.bash_completion` 파일에서 `[[ -f ~/.bash_completion.d/nnictl ]] && source ~/.bash_completion.d/nnictl` 행을 제거하면 된다.

# NNI에서 NAS 실험하기

NNI는 NAS 실험 프로세스를 위한 유연하고 통일된 인터페이스와, 실험 과정 및 결과를 한눈에 볼 수 있는 시각화 도구를 제공한다. 사용자는 이들을 이용해 새로운 NAS 알고리즘을 개발하거나, 각 NAS 알고리즘 별로 성능을 비교하는 등의 NAS 관련 실험을 편하게 할 수 있다.

NNI에서는 NAS 알고리즘을 두 부류로 구분한다.

- Classic NAS 알고리즘 : 전통적인 탐색 기반(Search-based) 접근법. 탐색 공간에서 샘플링된 후보 모델들을 독립적으로 학습시키는 방법.
- One-shot NAS 알고리즘 : 탐색 공간에 대해 "슈퍼넷(Supernet)"이 만들어지고, One-shot 학습법을 이용해 좋은 성능을 내는 후보 모델들을 생성하는 방법.

## Classic NAS 알고리즘

현재 버전(v1.8)에서 사용 가능한 Classic NAS 알고리즘은 다음과 같다.

- 무작위 탐색 (Random Search)
- PPO Tuner

사용자는 `nnictl` 명령어를 이용해 Classic NAS 알고리즘을 사용하는 실험을 수행할 수 있다.

## One-shot NAS 알고리즘

현재 버전(v1.8)에서 사용 가능한 One-shot NAS 알고리즘은 다음과 같다.

- ENAS
- DARTS
- P-DARTS
- SPOS
- CDARTS
- ProxylessNAS
- TextNAS

One-shot NAS 알고리즘은 `nnictl`을 사용하지 않는다.

NNI는 PyTorch[^4], Tensorflow 2.X를 지원한다.

NNI의 예제 코드를 돌리기 위해서는 tensorboard, PyTorch 1.2+[^4], git이 설치되어 있어야 한다.

[^4]: `BoolTensor`를 사용해야 하기 때문

"NNI API"를 이용하면 이외에도 다른 알고리즘 혹은 다른 데이터 셋을 사용하는 실험을 설계할 수 있다.

## 탐색 공간

### Search Space Zoo

NNI는 몇몇 사전 정의된 탐색 공간을 기본으로 제공한다. 이를 Search Space Zoo라 부른다. Search Space Zoo에는 다음 NAS Cell이 포함되어 있다.

- DartsCell
- ENAS micro
- ENAS macro
- NAS Bench 201

사용자는 Search Space Zoo를 이용해 빠르게 NAS 실험 결과를 재현할 수 있다.

### NNI API를 이용해 탐색 공간 만들기

NNI는 (뉴럴 네트워크의) 탐색 공간을 표현할 수 있는 통일된 API를 제공한다.

다음 코드를

"NAS API"를 사용하면 사용자가 직접 탐색 공간을 만들 수도 있다.







# SPOS ImageNet 예제 실행하기

우선 예제 코드를 다운받는다.

{% highlight bash %}
$ git clone https://github.com/microsoft/nni.git
{% endhighlight %}

예제 코드를 실행시키기에 앞서, 몇 가지를 다운받아야 한다.

먼저 NVIDIA DALI를 설치해야 한다. NVIDIA DALI는 다음과 같이 pip 명령어로 쉽게 설치할 수 있다.

{% highlight bash %}
$ pip install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda100
{% endhighlight %}

그리고 floops loopup table을 다운받아야 한다. 다음 링크에서 `op_flops_dict.pkl` 파일을 다운받아 `nni/examples/nas/spos/data/` 디렉토리 밑에 추가한다.

[Megvii's Onedrive](https://1drv.ms/u/s%21Am_mmG2-KsrnajesvSdfsq_cN48?e=aHVppN)

슈퍼넷을 다시 학습시키길 원하지 않는다면 위 링크에서 `Supernet/checkpoint-150000.pth.tar` 파일도 다운받아 `nni/examples/nas/spos/data/` 디렉토리 밑에 추가한다.

그리고 ImageNet도 다운받아 압축을 푼 상태로 `nni/examples/nas/spos/data/imagenet` 디렉토리 밑에 추가한다.

모든 것이 완료되면 `nni/examples/nas/spos/` 디렉토리는 다음과 같은 폴더 구조를 가지게 된다.

{% highlight text %}
spos
├── architecture_final.json
├── blocks.py
├── config_search.yml
├── data
│   ├── imagenet
│   │   ├── train
│   │   └── val
│   └── op_flops_dict.pkl
├── dataloader.py
├── network.py
├── readme.md
├── scratch.py
├── supernet.py
├── tester.py
├── tuner.py
└── utils.py
{% endhighlight %}

## 슈퍼넷 학습시키기

우선 학습에 앞서 `nni/examples/nas/spos/supernet.py`의 코드에 수정을 가해야 한다. 바로 돌리면 문법 오류가 난다.

55번째 줄 `mutator = SPOSSupernetTrainingMutator(model, flops_func=model.module.get_candidate_flops,`에서 `flop_func`에 `model.module.get_candidate_flops`를 넘기고 있는데, 이를 `model.get_candidate_flops`으로 바꿔야 한다.[^10]

[^10]: `module`을 제거한 것이다.

이제 다음 명령어로 `supernet.py` 파일을 실행해 슈퍼넷을 학습시킨다.

{% highlight bash %}
$ cd nni/examples/nas/spos/
$ python supernet.py --spos-preprocessing
{% endhighlight %}

만약 ImageNet의 경로가 `nni/examples/nas/spos/data/imagenet`가 아니라면, ImageNet의 경로를 다음과 같이 `--imagenet-dir` 옵션으로 줄 수 있다.

{% highlight bash %}
$ python supernet.py --imagenet-dir /cmsdata/ssd1/cmslab/imagenet --spos-preprocessing
{% endhighlight %}

만약 CUDA Out of Memory 오류가 뜨면 다음과 같이 `--batch-size` 옵션을 이용해 배치 크기를 줄일 수 있다. 기본값은 768이다.

{% highlight bash %}
$ python supernet.py --imagenet-dir /cmsdata/ssd1/cmslab/imagenet --batch-size 128 --spos-preprocessing
{% endhighlight %}

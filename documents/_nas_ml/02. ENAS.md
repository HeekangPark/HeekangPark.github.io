---
title: "ENAS (Efficient Neural Architecture Search)"
order: 2
date: "2020-09-24"
---

ENAS(Efficient Neural Architecture Search)는 H. Pham, et al.의 논문 \<Efficient Neural Architecture Search via Parameter Sharing\>에 등장한 NAS 기술이다.

# Efficient Neural Architecture Search via Parameter Sharing

## Introduction

- NAS(Neural Architecture Search)는 이미지 분류(Image Classification)와 언어 모델(Language Model)을 위한 모델 구조 설계에 성공적으로 적용되어옴
- NAS의 "RNN 컨트롤러"는 다음을 반복하는 반복문 안에서 학습됨
  - 컨트롤러는 우선 Candidate Architecture를 뽑음 : 이를 Child Model이라 함
  - 컨트롤러는 뽑은 Child Model을 수렴(Convergence)할 때까지 학습시켜 풀고자 하는 task에 대한 성능을 확인
  - 컨트롤러는 확인한 성능을 유도 신호(Guiding Signal)로 사용하여 더 유망한 Architecture를 찾는데 사용
- *문제 제기 : NAS는 놀라운 성과를 냈지만, Computation Cost가 너무 크다.*
- **저자들은 Child Model의 성능을 확인하기 위해 수렴할 때까지 학습시키는 것이 NAS의 Computational Bottleneck임을 관찰**
  - 성능 확인 후에는 Child Model의 학습된 Weight는 모두 폐기한다.
- **저자들은 
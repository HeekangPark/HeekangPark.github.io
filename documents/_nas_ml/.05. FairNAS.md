---
title: "FairNAS"
order: 5
date_created: "2020-10-10"
date_modified: "2021-02-15"
---

# 논문 분석

Xiangxiang Chu, Bo Zhang, Ruijun Xu, Jixiang Li, \<FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search\>, 2019

## Introduction

- NAS에서 네트워크의 성능을 평가하는 것은 중요
- weight-sharing 접근법들은 크게 두 가지로 구분할 수 있음
  - (최고 성능 모델의) 탐색과 (supernet의) 학습을 한번에(one stage) 동시에 하는 것
  - 탐색과 학습을 두 단계(two stage)로 따로따로 하는 것
    - 학습된 supernet은 최종 탐색의 평가자(evaluator)로서 동작
- weight-sharing이 비록 많이 사용되곤 있지만, weight sharing은 단단한 이론적 배경을 가지고 있지 않음
  - 더 논의되어야 할 사항들
    - 왜 밑바닥부터 학습시킨 "ground truth" 모델의 정확도와 supernet이 예측한 정확도의 범위 간 큰 차이가 있는가?
    - subnetwork를 과대평가하지도 과소평가하지도 않는 좋은 평가자(evaluator)를 어떻게 만들 수 있는가?
    - 왜 weight sharing 방식이 작동하는가?
- 저자들은 위 3가지 질문들에 대한 답을 two-stage weight-sharing 접근법에 대해 찾음
- 기여 내역
  - supernet이 불공평한 편향(unfair bias) 때문에 subnetwork의 성능을 잘못 평가한다는 것을 증명
    - 현재의 one-shot 접근법에서 이는 피할 수 없음
  - Expectation Fairness(EF), Strict Fairness(SF), 이렇게 두 단계(level)의 공정함 제약조건(fairness constraints)을 제안
    - EF와 SF는 supernet의 편향을 완화하도록 하고, 평가 capacity를 가속함
    - 기존 불공정한 접근법들에 비해 성능이 좋아짐
  - 공정함(fiarness) 측면에서 single-path supernet 학습의 validity의 근본 원인을 규명
    - 같은 layer의 다른 choice block은 상응하는 channel에서 유사한 feature map을 학습하게 됨
      - 그들의 높은 cosine similarity 때문
  - 저자들의 fair single-path 샘플링은 메모리를 적게 사용하고, 다양한 종류의 하드웨어 세팅에 대해서 GPU 비용을 선형적으로 상환(amortize)할 수 있음

## Fairness Taxonomy of Weight-sharing NAS

### Review of Biased Supernets

- One Stage 탐색법 : supernet 학습과 좋은 모델을 중첩해서(nested) 찾음
  - ENAS에서, LSTM controller의 샘플링 정책 $\pi(m, \theta)$와 샘플링된 subnetwork $m$은 alternative하게 학습되고, 학습된 정책 $\pi$에 의해 다시 최종 모델이 샘플링된다.
    - ($\pi$에 의해) validation 데이터의 mini batch에 대해 최고의 reward를 가진 모델이 최종 모델로 선정됨
  - DARTS는 supernet 학습과 탐색을 bi-level optimization으로 합침
    - 각 operation들은 그것의 중요도를 나타내는 계수들로 합쳐저 있음
  - 위 두 방법들은 모든 subnetwork들을 평등하지 않게 대함 → 최적화 과정에서 편향이 점점 커짐
    - 초기 성능이 좋은 architecture가 더 잘 샘플링되거나(ENAS) 높은 중요도 계수를 유지(DARTS)하게 됨 → 차선 혹은 더 안좋은 모델이 선택될 수 있음
    - 예를 들어, DARTS로 만들어진 architecture는 (bias 때문에) 다수의 skip connection을 가지고 있는 경우가 많음 → 최종 성능에 악영향
      - 다른 더 좋은 모델들이 선택받지 못함
- Two Stage 탐색법 : one-shot 방법. 학습된 supernet을 confident proxy로 이용
  - supernet을 이용해 모든 subnetwork의 진짜 성능을 예측
  - 믿을 만한 proxy supernet은 모든 (후보) 모델의 ground-truth 성능을 심각하게 과대평가하지도 과소평가하지도 않아야 함
  - 학습(training) 단계 이후의 탐색(searching) 단계는 학습 단계와 분리되어(decouple) 있음
    - 탐색 알고리즘으로 무작위 샘플링, 진화 알고리즘, 강화학습 등을 사용할 수 있음
- SMASH
  - architecture의 binary encoding으로부터 그것의 weight를 생성하는 hyper network(HyperNet $H$)를 제안
    - HyperNet은 탐색 공간 내 어떠한 architecture에 대해서도 weight를 생성할 수 있다는 점에서 기존의 supernet과 유사
  - 각 단계에서 architecture는 무작위로 샘플링되고, $H$로부터 생성된 weight를 기반으로 학습해 $H$를 업데이트함
  - 무작위로 샘플인된 architecture의 집합에 대해, 예측한 validation error와 참값(ground truth) 사이 상관 관계(correlation)가 존재하나, 범위에서 차이가 있음
- One-Shot
  - supernet에 대해 동적인 dropout rate를 사용해, 각 단계마다 (supernet의) 부분집합만 학습
  - 학습이 어려움
  - 참값(ground truth)과 상속받은 weight를 사용하는 submodel 간 성능 격차가 존재
  - SPOS(Single Path One Shot)는 학습을 할 때 supernet에서 균등하게(uniformly) single path를 샘플링함 → 모든 architecture는 동시에(simultaneously) 최적화됨
  - 그러나 이는 제한적인 공정함(fairness)만을 제공하는 방법이기 때문에 성능에 한계가 있음

### Evaluating Supernets by Ranking Ability

- Supernet이 얼마나 학습됐냐에 상관없이, 가장 중요한 것은 supernet이 후보 모델(candidate model)의 성능을 잘 예측(predict)하는지이다.
- 이 관점에서, 최근 연구들은 Kendall Tau($\tau$) metric를 이용해 weight-sharing supernet의 성능을 평가
  - One-shot 모델들과 혼자서 바닥부터 학습된 모델(Stand-alone trained model)들 간 순위(Ranking)의 상관관계를 측정
  - $-1 \le \tau \le 1$
    - $\tau = -1$ : 모델들의 순위가 완전히 반대로(totally reversed) 되어 있다.
    - $\tau = 1$ : 모델들의 순위가 완전히 유지되어(completely preserved) 있다.
    - $\tau = 0$ : 상관관계(correlation)가 전혀 없다.
  - 최근 NAS 접근법들은 $\tau$ metric에서 매우 낮은 성능을 보이고 있음 → 최근 접근법들은 많이 편향되어 있음
  - 이에 저자들은 One-shot 접근법에서 무엇이 이처럼 명백한 범위의 차이를 불러일으키는지 알아보려 함
    - 만약 supernet이 편향 없이 학습되었다면, evaluation confidence가 개선되고 accuracy gap을 줄일 수 있을 것인가?

### Formal Formulation of Fairness

- Definition 1. Equality Principle : supernet이 submodel들이 학습한 것과 같은 방식으로 학습해야 한다.
  - 정의 상, 각 단계에서 Single Path Model을 학습시키는 접근법만 Equality Principle을 만족시킴
    - DARTS(supernet의 모든 path를 동시에 학습시킴), One-Shot(일부 path를 동적으로 drop시킴), ProxylessNAS(path를 두 개 사용)들은 Equality Principle을 만족시키지 않음
  - $m$개의 choice block으로 이루어진 layer $L$개로 구성된 (일반적인) supernet에서 각 레이어마다 하나씩 블럭을 샘플링하면 한 모델이 만들어짐
  - 모델의 weight가 $n$번 업데이트된다고 한다면, 학습 과정을 $P(m, n, L)$이라 표현할 수 있다.
- 
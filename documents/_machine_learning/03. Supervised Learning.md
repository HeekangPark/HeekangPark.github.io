---
title: "지도학습 (Supervised Learning)"
order: 3
date: "2020-05-01"
---

# 지도학습의 과정

일반적으로 지도학습은 다음의 과정을 거치며 진행된다.

1. 데이터 수집 및 정제 : 학습을 위해 라벨링된 데이터를 (최대한 많이) 수집한다. 이후 수집한 데이터를 필요에 따라 가공[^1]한다.
2. 모델 결정 : 해결하고자 하는 과제 및 데이터의 종류, 성격 등을 토대로 사용하고자 하는 기계학습 모델을 결정한다. 모델을 입력값을 받아 출력값을 내놓는 함수로 이해할 수도 있는데, 그래서 모델을 가설 함수(Hypothesis Function)이라고도 부른다.[^2] 지도학습 모델에는 로지스틱 회귀(Logistic Regression), SVM(Support Vector Machine), 의사결정나무(Decision Tree), 랜덤 포레스트(Random Forest), NN(Nearest Neighbor), 인공신경망(Neural Network), 다중 레이어 퍼셉트론(Multilayer Perceptron, MLP) 등이 있다.
3. 파라미터 최적화(Parameter Optimization) : 데이터에 맞게 모델의 파라미터를 학습시킨다.

[^1]: 통계적 처리, 노이즈 제거, 특징점(feature) 추출 등
[^2]: 과학적 방법론(데이터 수집 - 가설 수립 - 가설 검증 실험 설계 - 가설 검증 - 가설 폐기 혹은 새로운 검증 실험 설계)에 익숙한 사람이라면 왜 "가설" 함수라 불리는지 이해할 수 있을 것이다. 

# 파라미터 최적화(Parameter Optimization)

위 과정 중 파라미터 최적화에 대해서 조금 더 알아보자.

지도학습을 위해 데이터를 수집해 다음과 같이 총 $n$개의 입력값 $\boldsymbol{x}(x_1, x_2, \dots, x_d)$와 정답(label) $y$의 쌍으로 이루어진 데이터 셋을 구성했다고 하자.

|   idx    |  $x_1$   |  $x_2$   | $\dots$  |  $x_d$   |       |   $y$    |
| :------: | :------: | :------: | :------: | :------: | :---: | :------: |
|    1     |    2     |    16    | $\dots$  |    7     |       |    6     |
|    2     |    3     |    6     | $\dots$  |    7     |       |    9     |
| $\vdots$ | $\vdots$ | $\vdots$ | $\ddots$ | $\vdots$ |       | $\vdots$ |
|   $n$    |    8     |    96    | $\dots$  |    21    |       |    2     |

이 데이터 셋에 대해 $p$개의 파라미터 $\boldsymbol{w}(w_1, w_2, \dots, w_p )$로 이루어진 모델 $f(\boldsymbol{w})$를 학습시키기로 하였다.

만약 이 모델이 잘 학습되었다면, 다음 식을 만족할 것이다.

$$f(\boldsymbol{x}\,;\,\boldsymbol{w}) \approx y$$

이 말을 조금 다르게 표현하면, 잘 학습된 모델에서는 $f(\boldsymbol{x}\,;\,\boldsymbol{w})$와 $y$ 간의 오차가 작다. 즉 수학적으로 **모델을 학습시킨다는 것은 $f(\boldsymbol{x}\,;\,\boldsymbol{w})$와 $y$ 간의 오차 $e$를 작게 만드는 과정**이다.

이제 우리는 "모델을 학습시킨다"는 추상적인 문제 대신, "오차를 최소화한다"라는 명확하고 구체적인 문제를 가지게 되었다. 그리고 오차를 최소화하는 문제는 전형적인 최적화 문제(Optimization Problem) 중 하나이다.(이 때문에 모델 학습 과정을 파라미터 최적화라 하는 것이다.)

## 오차 함수 (Error Function)

그렇다면 그 오차는 어떻게 구할까? 지도학습에서 오차는 오차 함수(Error Function)라는 함수를 이용하여 구한다. 오차 함수는 비용 함수(Cost Function), 손실 함수(Loss Function), 목표 함수(Objective Function)라고도 불린다. (모두 다 같은 의미이다.) 오차 함수는 $\boldsymbol{w}$에 대한 함수이다.

오차 함수에는 다양한 종류가 있는데, 평균제곱오차 (MSE, Mean of Squared Error), 크로스 엔트로피 (Cross Entropy)가 많이 사용된다. 해결하고자 하는 과제 및 데이터의 종류, 성격 등을 고려하여 적당한 오차 함수를 선택하여 학습하면 된다.

### 평균제곱오차 (MSE, Mean of Squared Error)

데이터의 총 개수가 $n$개라 했을 때, $i = 1, 2, ..., n$에 대해 입력값 $\boldsymbol{x_i}$와 해당 입력값의 레이블(출력값) $y_i$가 주어졌다고 하자. 이 데이터 셋에 대해 학습할 모델을 $f$라 할 때, 평균제곱오차는 다음과 같이 정의된다.

$$ \mathrm{Error} = \frac{1}{n} \sum_{i=1}^{n} (y_i - f(\boldsymbol{x_i}))^2 $$

이름 그대로 오차($y_i - f(\boldsymbol{x_i})$)를 제곱하여 모두 양수로 만든 후 평균을 구하는 함수이다. 지극히 직관적이고 합리적인 오차 함수여서 사실 별다른 설명이 필요 없다.

#### 평균제곱오차에서 "제곱"을 하는 이유

사족으로, 보통 평균제곱오차를 처음 배울 때 제곱을 하는 이유를 '음수를 없애기 위해서'라 배운다. 그러면 자연스럽게 드는 생각이 '왜 절대값이 아닌 제곱을 할까?'일 것이다.

결론부터 말하자면, 절대값의 평균으로 정의되는 평균절대오차(MAE, Mean Absolute Error)도 있다. 하지만 평균절대오차는 평균제곱오차에 비해 잘 사용되지 않는다. 그 이유는 오차 함수의 사용 목적을 생각해 보면 답이 나온다. 오차 함수는 문제 상황을 알려주는 함수다. 오차 함수로 문제 상황이 더 잘 드러나면 드러날수록 그 문제가 해결될 가능성이 커진다. 평균제곱오차의 제곱오차와 평균절대오차의 절대오차는 모두 수학적으로 나올 수 있는 최소값이 0이다.[^3] 즉, 제곱오차와 절대오차 모두 0에 가까울수록 좋은 값이다. 그렇다면 반대로, 0에서 멀어지면 멀어질수록 안좋은 값(문제 상황)이라 할 수 있다. 이때 절대오차는 0에서 멀어질수록 선형적으로 커지지만, 제곱오차는 그 값이 더 극적으로 커지므로 문제 상황이 더 부각되어 나타나게 된다. 그 결과 평균제곱오차를 사용할 때가 평균절대오차를 사용할 때에 비해 오차가 더 잘 수정되어 더 널리 사용되는 것이다.

[^3]: 주어진 데이터에 대해 나올 수 있는 오차의 최소값은 0이 아닐 수 있다.

### 크로스 엔트로피 (Cross Entropy)

추가 예정

## 최적화 방법

이제 우리의 목표는 $\boldsymbol{w}$에 대한 함수 $\mathrm{Error}(\boldsymbol{w})$가 언제 최소가 되는지, 즉 오차 함수를 최소값으로 만드는 $\boldsymbol{w}$를 찾는 것이다. 이 문제를 푸는 방법은 크게 두 가지가 있다. 첫 번째는 분석적 풀이법(Analytic Solution)이고, 두 번째는 수치 계산법(Numerical Solution)이다.

### 분석적 풀이법 (Analytic Solution)

분석적 풀이법은 오차 함수가 언제 최소값을 갖는지 수학적으로 푸는 것이다.

수학적으로 어떤 함수가 언제 최소값을 가지는지 어떻게 알 수 있을까? 예를 들어, 다음 이차함수를 생각해 보자.

$$f(x) = x^2 + 2x + 3 $$

중학교 시간에 배운 수학을 이용하면

$$f(x) = (x+1)^2 + 2$$

이므로 $x = -1$일 때 $f$는 최소값을 가짐을 알 수 있다.

$f$가 $x = -1$에서 최소값을 가진다는 것을 미적분을 이용해서도 보일 수 있다. $f$는 볼록함수(convex function)이므로, 최소값은 이 함수의 도함수(derivative)가 0이 되는 점에서 발생한다. 즉,

$$\frac{df}{dx} = 2x + 2 = 0$$

을 만족시키는 $x = -1$에서 최소값을 가짐을 알 수 있다.

다변수 함수에서는 [그라디언트(gradient)]({{ site.url }}/{{ site.baseurl }}calculus/그라디언트-gradient)를 이용하면 같은 풀이를 할 수 있다.

함수

$$f(x, y) = x^2 +xy - 2x - y^2$$

에 대해, 그라디언트는 

$$\nabla f(x, y) = [2x + y - 2, x - 2y] $$

이다. 이때 $f$의 최소점은 그라디언트의 각 원소가 0이 되는 점이다.

$$ \begin{cases}
2x + y - 2 = 0\\
x - 2y = 0\\
\end{cases} $$

위 연립방정식을 풀면

$$ x = \frac {4}{5},\quad y = \frac{2}{5} $$

이므로, 우리는 함수 $f(x, y) = x^2 +xy - 2x - y^2$가 (4/5, 2/5)에서 최소값을 가짐을 알 수 있다.


## 수치 계산법 (Numerical Solution)

수치 계산법은 정확한 해가 아닌 근사해를 구하는 것을 목적으로 하는 풀이이다. 분석적 풀이법이 수학적으로 정확한 답을 준다는 장점이 있지만, 다음의 상황에서는 적용하기 어려운 단점이 있다.

- 변수의 수가 너무 많은 경우 : 변수의 수가 너무 많은 경우 수학적으로 해를 구하는 과정에 너무 많은 컴퓨팅 파워가 요구된다.
- 최소점이 존재하지 않거나, 계산 불가능한 경우 : 함수가 볼록 함수가 아니거나, 불연속 등의 이유로 수학적으로 최소점을 계산할수 없는 경우가 있다.
- 그라디언트의 원소를 0으로 만드는 근을 구할 수 없거나 구하기 어려운 경우 : 연립방정식이 비선형연립방정식이어서 근을 수학적으로 구할 수 없거나, 선형연립방정식이어도 근이 존재하지 않는 경우, 근이 무수히 많은 경우 등이 있을 수 있다.

이 경우 수치 계산법이 유용한 방법이 될 수 있다.

수치 계산법에서는 한 번에 해를 구하는 분석적 풀이법과 다르게 알고리즘을 여러 번 반복하면서 점점 더 품질이 좋은 근사해를 구한다.

수치 계산법에는 다양한 방법이 있다.

- 경사 하강법(Gradient Descent Method)
- 뉴턴법(Newton Method)
- 가우스-뉴턴법(Gauss-Newton Method)
- Levenberg-Marquardt Method
- BFGS
- Conjugate Gradient Method
- 등등...

이 중 경사하강법이 가장 흔하게 쓰이는 방법이다. 경사하강법은 방법 특성상 최소값에 도달하지 못할 수도 있으나, 속도가 빠르고 연산량이 적어 현재 널리 쓰이고 있다.

### 경사 하강법 (Gradient Descent Method)

경사 하강법에서는 그라디언트의 반대 방향으로 가면 함수의 극소점을 찾을 수 있는 그라디언트의 성질을 사용한다.

분석적 풀이법과 동일하게 그라디언트를 사용하기에 헷갈릴 수 있는데, 분석적 풀이법은 그라디언트의 각 원소를 0으로 만드는 값(= 해)을 연립방정식을 풀어 찾는 방법이었다면, 경사 하강법은 그라디언트와 극소점 간의 성질을 이용하여 점진적으로 근사해를 찾아가는 방법이다.

경사 하강법에서는 다음 식으로 파라미터를 업데이트한다.

$$ \boldsymbol{w_{new}} = \boldsymbol{w_{old}} - \eta \nabla \boldsymbol{w_{old}} $$

이때 $\eta$는 그리스 문자 에타(eta)로서 학습률(learning rate)을 나타낸다. 학습률은 한 번에 파라미터를 얼마나 업데이트할 지를 나타내는 하이퍼파라미터이다.

학습률이 크면...

- 한 번의 업데이트로 파라미터가 크게 바뀐다.
- 최소값으로 다가가는 속도가 빠르다. 최소값에 더 적은 시간으로 도달할 수 있다.
- 최소값이 아닌 극소값(local minimum)으로 빠지더라도 탈출할 가능성이 생긴다.
- 최소값을 지나칠 수도 있다.

학습률이 작으면...
- 한 번의 업데이트로 파라미터가 작게 바뀐다.
- 최소값으로 다가가는 속도가 느리다. 최소값 도달에 더 많은 시간이 걸린다.
- 최소값이 아닌 극소값에 빠질 경우 탈출이 어렵다.
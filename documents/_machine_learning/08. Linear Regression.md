---
title: "단순 선형 회귀 (Simple Linear Regression)"
order: 8
date: "2020-05-14"
---

지도학습으로 풀 수 있는 문제 중 하나인 단순 선형 회귀(Simple Linear Regression Model) 문제를 풀어보자.

# 문제 상황

독립변수 $x$와 종속변수 $y$에 대해 다음과 같이 데이터가 주어졌다고 하자.

|  $x$  |  $y$  |       |  $x$  |  $y$  |
| :---: | :---: | :---: | :---: | :---: |
| 2.96  | 4.12  |       | 8.00  | 6.28  |
| 1.59  | 3.05  |       | 4.22  | 5.02  |
| 5.18  | 5.01  |       | 5.57  | 5.03  |
| 1.18  | 3.19  |       | 4.75  | 4.75  |
| 1.69  | 3.40  |       | 7.96  | 6.43  |
| 1.80  | 3.72  |       | 4.47  | 4.24  |
| 3.04  | 4.21  |       | 2.67  | 3.75  |
| 3.11  | 3.76  |       | 5.48  | 5.55  |
| 0.80  | 2.58  |       | 8.77  | 6.95  |
| 4.77  | 4.46  |       | 2.72  | 4.35  |
| 2.81  | 3.77  |       | 2.97  | 3.99  |
| 9.74  | 7.58  |       | 7.77  | 6.60  |
| 4.10  | 4.48  |       | 5.85  | 5.70  |
| 2.50  | 3.67  |       | 7.01  | 6.07  |
| 6.36  | 5.69  |       | 2.05  | 3.47  |
| 0.02  | 2.57  |       | 8.19  | 7.00  |
| 0.08  | 2.27  |       | 8.80  | 7.22  |
| 9.76  | 7.40  |       | 9.47  | 7.09  |
| 1.55  | 3.10  |       | 3.73  | 4.84  |
| 3.60  | 4.18  |       | 2.50  | 3.63  |

{% include caption-img.html src="simple-linear-regression-data.png" title="Fig.01 산점도" description="독립변수 $x$와 종속변수 $y$에 대한 산점도" %}

# 모델 설계 : 단순 선형 회귀 모델 (Simple Linear Regression Model)

산점도에서 볼 수 있듯이 $x$, $y$ 간에는 아주 강한 선형 상관관계가 있다. 이를 바탕으로 다음과 같이 모델을 세울 수 있다.

$$y = f(x) = w_1 x + w_0$$

이 모델을 단순 선형 회귀 모델(Simple Linear Regression Model)이라 한다. 단순 선형 회귀 모델은 독립 변수와 종속 변수가 1개씩 있고, 모델의 차수가 일차식인 모델이다.

위 모델을 다음과 같이 쓸 수도 있다.

$$y = f(x) = w_1 x_1 + w_0 x_0$$

위와 같이 $x$를 $x_1$으로 (이름을) 바꾸고, 항상 1인 변수 $x_0$를 추가한다. 이렇게 하면 이 모델을 다음과 같이 이해할 수 있다.

$$y = f(x) = \boldsymbol{w}^\intercal \cdot \boldsymbol{x} = \begin{bmatrix} w_0\\w_1\end{bmatrix} ^\intercal  \cdot \begin{bmatrix} x_0\\x_1\end{bmatrix}$$

# 파리미터 최적화

## 오차 함수 : 평균 제곱 오차(MSE, Mean of Squared Error)

단순 선형 회귀 모델의 파라미터를 최적화하기 위해서는 [평균 제곱 오차(MSE, Mean of Squared Error)]({{ site.url }}{{ site.baseurl }}/machine_learning/03-supervised-learning/#kramdown_평균제곱오차-mse-mean-of-squared-error)를 사용한다.

총 $n$쌍의 입력 데이터-출력 데이터(레이블) 쌍 ($\boldsymbol{x}_i$, $y_i$) ($i=1, 2, \cdots, n)$가 있는 데이터 셋과 모델 $f$가 주어졌을 때, 모델에 대한 평균 제곱 오차 $J(\boldsymbol{w})$는 다음과 같이 정의된다.

$$J(\boldsymbol{w}) = \frac {1}{n} \sum _{i=1} ^{n} (y_i - f(x_i))^2$$

## 분석적 풀이법 (Analytic Solution)

$J(\boldsymbol{w})$를 $j$번째 파라미터 $w_j$에 대해 편미분하면 다음과 같다. ($j = 0, 1$)

$$
\begin{align}
\frac {\partial}{\partial w_j} J(\boldsymbol{w}) 
&= \frac {\partial}{\partial w_j} \left( \frac {1}{n} \sum _{i=1} ^{n} (y_i - f(x_i))^2 \right) \\[10pt]
&= \frac {1}{n} \sum _{i=1} ^{n} \left( \frac {\partial}{\partial w_j} (y_i - f(x_i))^2 \right) \\[10pt]
&= \frac {1}{n} \sum _{i=1} ^{n} \left( 2 (y_i - f(x_i)) \cdot -\frac {\partial}{\partial w_j} f(x_i) \right) \\[10pt]
&= \frac {1}{n} \sum _{i=1} ^{n} ( 2 (y_i - f(x_i)) \cdot -x_{ij} )\\[10pt]\\[10pt]
\end{align}
$$

$J(\boldsymbol{w})$를 최소로 만드려면 모든 $j$에 대해 $\partial J / \partial w_j$를 0으로 만드는(최소화하는) $\boldsymbol{w}$을 찾으면 된다. 즉,

$$\frac {\partial}{\partial w_j} J(\boldsymbol{w}) = \frac {1}{n} \sum _{i=1} ^{n} ( 2 (y_i - f(x_i)) \cdot -x_{ij} ) = 0$$

식을 변형하면

$$\sum _{i=1} ^{n} y_i \cdot x_{ij} = \sum _{i=1} ^{n} f(x_i) \cdot x_{ij} $$

## 수치 계산법 (Numerical Solution)
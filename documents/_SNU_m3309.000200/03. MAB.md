---
title: "L03. MAB(Multi-armed Bandits)"
order: 3
date: "2021-03-15"
---

# Evaluative Feedback vs. Instructive Feedback

RL과 지도학습(Supervised Learning)의 큰 차이 중 하나가, RL은 Evaluative Feedback을 이용해 학습되고 지도학습은 Instructive Feedback을 이용해 학습이 진행된다는 것이다. 

Evaluative Feedback은 (에이전트가 취한 행동에 대한 결과값으로서) 취한 행동이 얼마나 좋은지를 알려주는 값이다. 단 Evaluative Feedback은 어떤 행동이 최고의 행동인지 알려주진 않는다. Evaluative Feedback은 에이전트가 이때까지 취한 행동에 대해 종속적인 값이다. RL은 이 값을 이용해 학습을 진행한다.

한편 Instructive Feedback은 어떤 행동이 맞는 행동인지(= 최고의 행동인지)를 알려주는 값이다. 이 값은 에이전트가 이때까지 취한 행동과는 독립적인 값이다.[^1] 지도학습은 이 값을 이용해 학습을 진행한다.

[^1]: 원래 피드백이라는 단어는 어떤 행동을 했을 때 그에 대한 결과값을 뜻하는 용어이다. 그렇기에 Evaluative Feedback에서의 피드백이라는 단어는 적절한 단어다. 말 그대로 에이전트의 행동에 의해 에이전트를 둘러싸고 있는 환경이 그 결과로서 제공하는 값이기 때문이다. 그러나 Instructive Feedback의 경우 행동과 관련없는 독립적인 값으로, 피드백이라는 단어가 사실 적절치 않다. Instructive Feedback이라는 용어는 순전히 Evaluative Feedback에 대한 반댓말로서, Evaluative Feedback과 대구(對句)를 이루고자 Feedback이라는 단어를 쓴 것이다. 

# k-armed Bandit Problem

다음 상황을 생각해 보자.

> 철수는 미국 여행 중 라스베가스 공항을 경유하게 되었다. 심심한 철수는 다음 비행기가 올 때까지 2시간동안 라스베가스 공항의 명물, 슬롯머신을 당겨 보기로 했다. 다행히 공항에 사람이 별로 없어서 철수는 10대의 슬롯머신을 전세내고 사용할 수 있다. 1번 슬롯 머신은 0.001, 2번 슬롯 머신은 0.07, ... 이런 식으로 각 슬롯머신마다 잭팟이 터질 확률은 고정되어 있고 또 각자 다르다. 한 번에 한 대의 슬롯 머신을 당길 수 있을 때, 철수는 어떤 전략을 취해야 가장 많은 돈을 딸 수 있을까?

이 문제는 전형적인 [Exploration](/SNU_m3309.000200/02-introduction#kramdown_exploitation-vs-exploration)과 [Exploitation]((/SNU_m3309.000200/02-introduction#kramdown_exploitation-vs-exploration)이 충돌하는 문제이다. 철수는 2시간동안 하나의 슬롯 머신만을 계속 당기는 선택을 할 수도 있지만, 현재 잡고 있는 슬롯 머신이 가장 높은 잭팟 확률을 가진 슬롯 머신이 아닐 수도 있다. 또는 10개의 슬롯 머신을 각각 10번씩 당겨 보아 가장 확률이 높은 슬롯 머신을 찾아보는 선택을 할 수도 있겠지만, 10의 시행으로는 각 슬롯 머신의 확률을 정확히 아는데 한계가 있을 것이다. 각 슬롯 머신을 시험해보는 횟수를 늘리면 조금 더 정확한 확률을 구할 수 있겠지만, 이 경우 탐색에 너무 많은 시간을 사용하게 되어 막상 돈을 얼마 벌진 못할 것이다.

이와 같이 k개의 선택 가능한 옵션이 있고, 한 옵션을 선택하면 고정된 확률 분포(stationary probability distribution)에 따라 숫자로 된 보상(numerical reward)을 받을 수 있을 때, 특정 시간 동안 받을 전체 보상을 최대화하는 문제를 k-armed Bandit Problem이라 한다.[^2]

[^2]: one-armed bandit(한 손 달린 강도)는 미국에서는 슬롯 머신을 부르는 속어이다(bandit은 도둑, 강도라는 뜻이다). k-armed Bandit Problem은 여기에서 이름을 따온 것이다. 즉 k-armed Bandit Problem이라 하면 레버가 k개 있는 슬롯 머신에서, k개의 레버 중 하나를 골라 당기는 과정을 여러 번 반복할 때 받을 전체 보상을 최대화하는 문제를 뜻한다.


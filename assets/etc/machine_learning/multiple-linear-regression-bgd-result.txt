Before Training...
w = [-1.7688457055759508, 0.07555227120810952, -1.1306297028053423, -0.6514301669047348, -0.8931156263199002, -1.2741009767999079, -0.06115443195334841, 0.06451384411861422, 0.4101129497994469, -0.572882490081088, -0.8013336248612375, 1.3120351922129225, 1.2746988741941558, -1.2143576048675497]
Training Loss = 392.2159853295022
Validation Loss = 12616.209620826941
                training                |               validation               
     predict_y             true_y       |     predict_y             true_y       
     -0.141992           -0.009659      |     -7.722083           -1.309633      
      2.148229           -0.267505      |     -7.135726            0.409341      
      2.819930            1.139906      |     -9.540326           -0.740223      
      4.432565            1.000239      |     -12.657010           0.366367      
      4.088140            1.301060      |     -16.055317          -0.976582      
      4.091320            0.495290      |     -17.435815          -0.740223      
     -1.821722           -0.127838      |     -19.733918          -0.665018      
     -2.842757            0.323393      |     -11.400887          -0.836915      
     -4.993001           -0.815428      |     -19.079316          -1.836069      
     -2.689193           -0.557582      |     -19.859117          -1.814582      

After Training...
w = [-0.65065689206561, 0.23831936264630915, -0.5749827561822578, -0.09628045558492378, -0.15763039037423165, -0.3698705655146483, 0.1225395382283202, 0.389620247399685, -0.056799799387965845, -0.08280645086183337, -0.1839070611507291, 0.2519622277435441, 0.3351691271094846, -0.9325309987556846]
Training Loss = 3.1091011723311244
Validation Loss = 20.48242449983741
                training                |               validation               
     predict_y             true_y       |     predict_y             true_y       
      0.239262           -0.009659      |     -2.118517           -1.309633      
      0.719351           -0.267505      |     -0.956036            0.409341      
      1.268487            1.139906      |     -3.018112           -0.740223      
      1.391145            1.000239      |     -2.774974            0.366367      
      1.224427            1.301060      |     -1.906807           -0.976582      
      1.156625            0.495290      |     -4.213375           -0.740223      
     -0.887939           -0.127838      |     -6.235494           -0.665018      
     -1.374950            0.323393      |     -2.375668           -0.836915      
     -2.963231           -0.815428      |     -5.545262           -1.836069      
     -1.362050           -0.557582      |     -5.518906           -1.814582      
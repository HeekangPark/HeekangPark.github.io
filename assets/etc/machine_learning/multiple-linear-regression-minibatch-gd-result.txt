Before Training...
w = [-1.7688457055759508, 0.07555227120810952, -1.1306297028053423, -0.6514301669047348, -0.8931156263199002, -1.2741009767999079, -0.06115443195334841, 0.06451384411861422, 0.4101129497994469, -0.572882490081088, -0.8013336248612375, 1.3120351922129225, 1.2746988741941558, -1.2143576048675497]
Training Loss = 392.2159853295022
Validation Loss = 12616.209620826941
                training                |               validation               
     predict_y             true_y       |     predict_y             true_y       
     -0.141992           -0.009659      |     -7.722083           -1.309633      
      2.148229           -0.267505      |     -7.135726            0.409341      
      2.819930            1.139906      |     -9.540326           -0.740223      
      4.432565            1.000239      |     -12.657010           0.366367      
      4.088140            1.301060      |     -16.055317          -0.976582      
      4.091320            0.495290      |     -17.435815          -0.740223      
     -1.821722           -0.127838      |     -19.733918          -0.665018      
     -2.842757            0.323393      |     -11.400887          -0.836915      
     -4.993001           -0.815428      |     -19.079316          -1.836069      
     -2.689193           -0.557582      |     -19.859117          -1.814582      

After Training...
w = [-0.7804591025051804, 0.25758874516685903, -0.6770105274522087, -0.11932210645176851, -0.22681200746319055, -0.42595707327282556, 0.09231277692864227, 0.3981453744076262, -0.047456357010958454, -0.10435977793054906, -0.21649417037835356, 0.3785898294284877, 0.4201418715172932, -0.9427368738081758]
Training Loss = 5.932636887587184
Validation Loss = 46.26676646026161
                training                |               validation               
     predict_y             true_y       |     predict_y             true_y       
      0.044599           -0.009659      |     -2.171301           -1.309633      
      0.775220           -0.267505      |     -1.155815            0.409341      
      1.286577            1.139906      |     -3.257729           -0.740223      
      1.498223            1.000239      |     -3.320737            0.366367      
      1.329127            1.301060      |     -2.667299           -0.976582      
      1.286529            0.495290      |     -5.057161           -0.740223      
     -1.079170           -0.127838      |     -7.015349           -0.665018      
     -1.569565            0.323393      |     -2.747105           -0.836915      
     -3.171184           -0.815428      |     -6.174701           -1.836069      
     -1.568261           -0.557582      |     -6.409612           -1.814582      